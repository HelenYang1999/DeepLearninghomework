{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9MgPrpBI36B"
      },
      "source": [
        "# Assignment 2: DenseNet with CIFAR10 Dataset by TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdKz6v44I36C"
      },
      "source": [
        "In this assignment, you are required to implement DenseNet to classify images from the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) by using TensorFlow with Keras. DenseNet is very well-known and therefore it has been implemented and pre-trained by Keras. You are also required to load and test the pre-trained models, and compare them with your models.\n",
        "\n",
        "First of all, read the DenseNet paper. DenseNet was originally proposed in 2016 by Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger in the following paper:\n",
        "https://arxiv.org/abs/1608.06993\n",
        "\n",
        "The process will be broken down into the following steps:\n",
        ">1. Answer a short question about DenseNet. (10 marks)\n",
        "2. Load and visualize the data.\n",
        "3. Implement your models. (30 marks)\n",
        "4. Train and evaluate your models. (25 marks)\n",
        "5. Load the pre-trained models from Keras and evaluate them. (15 marks)\n",
        "6. Analysis your results. (20 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ila4LbgmI36D"
      },
      "source": [
        "---\n",
        "## 1. Answer a short question (20 marks)\n",
        "\n",
        "Now that you know what DenseNet is all about, let's compare it to VGG.\n",
        "Both VGG and DenseNet papers describe several variations of their models that differ by their depth.\n",
        "For example, VGG16 and VGG19, DenseNet-121 and DenseNet-169 are four examples from these papers.\n",
        "\n",
        "Aside from difference in network depth, how is the architecture of DenseNet different from that of VGG? Please enter your answer in the next cell (approximately 100-200 words, both English and Chinese are acceptable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0tAnDb2I36D"
      },
      "source": [
        "VGG网络是基于AlexNet的改进，主要思想是用多个小卷积核来代替一个大卷积核，使网络结构变得\n",
        "复杂，学到更多信息的同时参数变得更少，网络变得更有效率。DenseNet主要是基于ResNet的改进，通过对特征图的重用，达到更浅的网络、更少的参数、更好的性能。DenseNet在设计网络的时候，也借鉴了VGG的结构，卷积层主要使用的是3×3的小卷积核。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcw96NNiI36E"
      },
      "source": [
        "---\n",
        "## 2. Load and visualize the data.\n",
        "\n",
        "The data is directly loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmFA3LcQI36E",
        "outputId": "55c335b0-3335-4502-be0c-888c1a8d522a"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# load the CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# mormalize data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(y_train[0])\n",
        "# convert class vectors to binary class matrices.\n",
        "#独热编码，将6转换成[0,0,0,0,0,0,1,0,0,0]\n",
        "# y_train = to_categorical(y_train, num_classes)\n",
        "# print('y_train shape:', y_train.shape)\n",
        "# print(y_train[0])\n",
        "from tensorflow.keras.datasets import cifar10from tensorflow.keras.datasets import cifar10# y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n",
            "[6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxQzyXibI36I",
        "outputId": "6da57f4e-f917-45b7-e887-6a7eb1de9298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape((50000, 32, 32, 3)).astype('float32') / 255\n",
        "x_test = x_test.reshape((10000, 32, 32, 3)).astype('float32') / 255\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AixYOkFyI36L",
        "outputId": "e2e4235c-baf9-4642-a93c-e91d2b69a14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3612f96da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QogGM03yI36N"
      },
      "source": [
        "---\n",
        "## 3. Implement your models (30 marks)\n",
        "\n",
        "In this task, you are required to implement DenseNet-121 and DenseNet-169 as depicted in the original paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5pGyBOJwI36O",
        "outputId": "f529c856-2266-4a27-f4a2-3d5ce8b448fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# implement the code of your DenseNet-121 model here.\n",
        "#https://keras.io/zh/layers/convolutional/\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#https://keras.io/zh/layers/writing-your-own-keras-layers/  Keras2.0needed\n",
        "#2.2.4-tf Satisfied\n",
        "\n",
        "# 瓶颈层，相当于每一个稠密块中若干个相同的H函数\n",
        "class BottleNeck(layers.Layer):\n",
        "    # growth_rate对应的是论文中的增长率k，指经过一个BottleNet输出的特征图的通道数；drop_rate指失活率。\n",
        "    def __init__(self, growth_rate, drop_rate):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv1 = layers.Conv2D(filters=4 * growth_rate,  # 使用1*1卷积核将通道数降维到4*k\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding=\"same\")\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.conv2 = layers.Conv2D(filters=growth_rate,  # 使用3*3卷积核，使得输出维度（通道数）为k\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=1,\n",
        "                                            padding=\"same\")\n",
        "        self.dropout = layers.Dropout(rate=drop_rate)\n",
        "        # 将网络层存入一个列表中\n",
        "        self.listLayers = [self.bn1,\n",
        "                           self.relu,\n",
        "                           self.conv1,\n",
        "                           self.bn2,\n",
        "                           self.relu,\n",
        "                           self.conv2,\n",
        "                           self.dropout]\n",
        "\n",
        "    def call(self, x):\n",
        "        y = x\n",
        "        for layer in self.listLayers.layers:\n",
        "            y = layer(y)\n",
        "        # 每经过一个BottleNet，将输入和输出按通道连结。作用是：将前l层的输入连结起来，作为下一个BottleNet的输入。\n",
        "        y = layers.concatenate([x, y], axis=-1)\n",
        "        return y\n",
        "\n",
        "# 稠密块，由若干个相同的瓶颈层构成\n",
        "class DenseBlock(layers.Layer):\n",
        "    # num_layers表示该稠密块存在BottleNet的个数，也就是一个稠密块的层数L\n",
        "    def __init__(self, num_layers, growth_rate, drop_rate=0.5):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.growth_rate = growth_rate\n",
        "        self.drop_rate = drop_rate\n",
        "        self.listLayers = []\n",
        "        # 一个DenseBlock由多个相同的BottleNeck构成，我们将它们放入一个列表中。\n",
        "        for _ in range(num_layers):\n",
        "            self.listLayers.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer in self.listLayers.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# 过渡层\n",
        "class TransitionLayer(layers.Layer):\n",
        "    # out_channels代表输出通道数\n",
        "    def __init__(self, out_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.conv = layers.Conv2D(filters=out_channels,\n",
        "                                           kernel_size=(1, 1),\n",
        "                                           strides=1,\n",
        "                                           padding=\"same\")\n",
        "        self.pool = layers.MaxPool2D(pool_size=(2, 2),   # 2倍下采样\n",
        "                                              strides=2,\n",
        "                                              padding=\"same\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bn(inputs)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "# DenseNet整体网络结构\n",
        "class DenseNet(tf.keras.Model):\n",
        "    # num_init_features:代表初始的通道数，即输入稠密块时的通道数\n",
        "    # growth_rate:对应的是论文中的增长率k，指经过一个BottleNet输出的特征图的通道数\n",
        "    # block_layers:每个稠密块中的BottleNet的个数\n",
        "    # compression_rate:压缩因子，其值在(0,1]范围内\n",
        "    # drop_rate：失活率\n",
        "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n",
        "        super(DenseNet, self).__init__()\n",
        "        # 第一层，7*7的卷积层，2倍下采样。\n",
        "        self.conv = layers.Conv2D(filters=num_init_features,\n",
        "                                           kernel_size=(7, 7),\n",
        "                                           strides=2,\n",
        "                                           padding=\"same\")\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        # 最大池化层，3*3卷积核，2倍下采样\n",
        "        self.pool = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n",
        "        self.relu = layers.ReLU()\n",
        "        # 稠密块 Dense Block(1)\n",
        "        self.num_channels = num_init_features\n",
        "        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "        # 该稠密块总的输出的通道数\n",
        "        self.num_channels += growth_rate * block_layers[0]\n",
        "        # 对特征图的通道数进行压缩\n",
        "        self.num_channels = compression_rate * self.num_channels\n",
        "        # 过渡层1，过渡层进行下采样\n",
        "        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n",
        "\n",
        "        # 稠密块 Dense Block(2)\n",
        "        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "        self.num_channels += growth_rate * block_layers[1]\n",
        "        self.num_channels = compression_rate * self.num_channels\n",
        "        # 过渡层2，2倍下采样，输出：14*14\n",
        "        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n",
        "\n",
        "        # 稠密块 Dense Block(3)\n",
        "        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "        self.num_channels += growth_rate * block_layers[2]\n",
        "        self.num_channels = compression_rate * self.num_channels\n",
        "        # 过渡层3，2倍下采样\n",
        "        self.transition_3 = TransitionLayer(out_channels=int(self.num_channels))\n",
        "\n",
        "        # 稠密块 Dense Block(4)\n",
        "        self.dense_block_4 = DenseBlock(num_layers=block_layers[3], growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "\n",
        "        # 全局平均池化，输出size：1*1\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        # 全连接层，进行10分类\n",
        "        self.fc = layers.Dense(units=10, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.dense_block_1(x)\n",
        "        x = self.transition_1(x)\n",
        "        x = self.dense_block_2(x)\n",
        "        x = self.transition_2(x)\n",
        "        x = self.dense_block_3(x)\n",
        "        x = self.transition_3(x,)\n",
        "        x = self.dense_block_4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "def densenet_121():\n",
        "    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 24, 16], compression_rate=0.5, drop_rate=0.5)\n",
        "\n",
        "densenet_121 = densenet_121()\n",
        "\n",
        "densenet_121.build(input_shape=(50000, 32, 32, 3))\n",
        "\n",
        "densenet_121.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dense_net_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_408 (Conv2D)          multiple                  9472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_408 (Bat multiple                  256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling multiple                  0         \n",
            "_________________________________________________________________\n",
            "re_lu_210 (ReLU)             multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_block_12 (DenseBlock)  multiple                  339264    \n",
            "_________________________________________________________________\n",
            "transition_layer_9 (Transiti multiple                  33920     \n",
            "_________________________________________________________________\n",
            "dense_block_13 (DenseBlock)  multiple                  931968    \n",
            "_________________________________________________________________\n",
            "transition_layer_10 (Transit multiple                  133376    \n",
            "_________________________________________________________________\n",
            "dense_block_14 (DenseBlock)  multiple                  2877696   \n",
            "_________________________________________________________________\n",
            "transition_layer_11 (Transit multiple                  528896    \n",
            "_________________________________________________________________\n",
            "dense_block_15 (DenseBlock)  multiple                  2188800   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_7 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  10250     \n",
            "=================================================================\n",
            "Total params: 7,053,898\n",
            "Trainable params: 6,972,298\n",
            "Non-trainable params: 81,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX9W5amaI36Q",
        "outputId": "ca94a189-f1b9-460d-e605-6edc6c4e558c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# implement the code of your DenseNet-169 model here.\n",
        "def densenet_169():\n",
        "    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 32, 32], compression_rate=0.5, drop_rate=0.5)\n",
        "\n",
        "densenet_169 = densenet_169()\n",
        "\n",
        "densenet_169.build(input_shape=(50000, 32, 32, 3))\n",
        "\n",
        "densenet_169.summary()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dense_net_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_528 (Conv2D)          multiple                  9472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_528 (Bat multiple                  256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling multiple                  0         \n",
            "_________________________________________________________________\n",
            "re_lu_272 (ReLU)             multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_block_16 (DenseBlock)  multiple                  339264    \n",
            "_________________________________________________________________\n",
            "transition_layer_12 (Transit multiple                  33920     \n",
            "_________________________________________________________________\n",
            "dense_block_17 (DenseBlock)  multiple                  931968    \n",
            "_________________________________________________________________\n",
            "transition_layer_13 (Transit multiple                  133376    \n",
            "_________________________________________________________________\n",
            "dense_block_18 (DenseBlock)  multiple                  4377600   \n",
            "_________________________________________________________________\n",
            "transition_layer_14 (Transit multiple                  824960    \n",
            "_________________________________________________________________\n",
            "dense_block_19 (DenseBlock)  multiple                  5999616   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_8 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  16650     \n",
            "=================================================================\n",
            "Total params: 12,667,082\n",
            "Trainable params: 12,512,010\n",
            "Non-trainable params: 155,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs06sYdFI36T"
      },
      "source": [
        "---\n",
        "## 4. Train and evaluate your models. (25 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNc7Zw61I36T"
      },
      "source": [
        "### 4.1 Train your models. (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tPT2pIVcI36U",
        "outputId": "3e68494e-7485-4728-c35c-7508c0703e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# implement your code here.\n",
        "#Train densenet_121\n",
        "\n",
        "densenet_121.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = densenet_121.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=30,verbose=2,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "704/704 - 29s - loss: 1.4656 - accuracy: 0.4719 - val_loss: 3.2847 - val_accuracy: 0.2366\n",
            "Epoch 2/30\n",
            "704/704 - 26s - loss: 1.2969 - accuracy: 0.5346 - val_loss: 1.8024 - val_accuracy: 0.3746\n",
            "Epoch 3/30\n",
            "704/704 - 27s - loss: 1.1703 - accuracy: 0.5835 - val_loss: 1.7608 - val_accuracy: 0.3746\n",
            "Epoch 4/30\n",
            "704/704 - 26s - loss: 1.0680 - accuracy: 0.6188 - val_loss: 1.7015 - val_accuracy: 0.3848\n",
            "Epoch 5/30\n",
            "704/704 - 26s - loss: 0.9847 - accuracy: 0.6522 - val_loss: 2.3902 - val_accuracy: 0.2970\n",
            "Epoch 6/30\n",
            "704/704 - 26s - loss: 0.9177 - accuracy: 0.6768 - val_loss: 1.6909 - val_accuracy: 0.4736\n",
            "Epoch 7/30\n",
            "704/704 - 26s - loss: 0.8564 - accuracy: 0.6986 - val_loss: 2.1093 - val_accuracy: 0.4742\n",
            "Epoch 8/30\n",
            "704/704 - 26s - loss: 0.8007 - accuracy: 0.7200 - val_loss: 1.9798 - val_accuracy: 0.4348\n",
            "Epoch 9/30\n",
            "704/704 - 26s - loss: 0.7508 - accuracy: 0.7371 - val_loss: 0.8776 - val_accuracy: 0.7036\n",
            "Epoch 10/30\n",
            "704/704 - 26s - loss: 0.7062 - accuracy: 0.7536 - val_loss: 1.0302 - val_accuracy: 0.6600\n",
            "Epoch 11/30\n",
            "704/704 - 26s - loss: 0.6697 - accuracy: 0.7653 - val_loss: 1.1796 - val_accuracy: 0.6586\n",
            "Epoch 12/30\n",
            "704/704 - 26s - loss: 0.6340 - accuracy: 0.7772 - val_loss: 1.5935 - val_accuracy: 0.5402\n",
            "Epoch 13/30\n",
            "704/704 - 26s - loss: 0.6069 - accuracy: 0.7878 - val_loss: 2.1036 - val_accuracy: 0.4794\n",
            "Epoch 14/30\n",
            "704/704 - 26s - loss: 0.5736 - accuracy: 0.7979 - val_loss: 5.4402 - val_accuracy: 0.3084\n",
            "Epoch 15/30\n",
            "704/704 - 26s - loss: 0.5464 - accuracy: 0.8073 - val_loss: 1.2056 - val_accuracy: 0.6536\n",
            "Epoch 16/30\n",
            "704/704 - 26s - loss: 0.5190 - accuracy: 0.8165 - val_loss: 2.4351 - val_accuracy: 0.4786\n",
            "Epoch 17/30\n",
            "704/704 - 26s - loss: 0.4947 - accuracy: 0.8255 - val_loss: 1.6616 - val_accuracy: 0.6002\n",
            "Epoch 18/30\n",
            "704/704 - 26s - loss: 0.4621 - accuracy: 0.8362 - val_loss: 1.7213 - val_accuracy: 0.6036\n",
            "Epoch 19/30\n",
            "704/704 - 26s - loss: 0.4384 - accuracy: 0.8458 - val_loss: 3.4511 - val_accuracy: 0.4880\n",
            "Epoch 20/30\n",
            "704/704 - 26s - loss: 0.4189 - accuracy: 0.8508 - val_loss: 6.9277 - val_accuracy: 0.2104\n",
            "Epoch 21/30\n",
            "704/704 - 26s - loss: 0.4032 - accuracy: 0.8574 - val_loss: 1.2410 - val_accuracy: 0.6916\n",
            "Epoch 22/30\n",
            "704/704 - 26s - loss: 0.3720 - accuracy: 0.8695 - val_loss: 1.1232 - val_accuracy: 0.7308\n",
            "Epoch 23/30\n",
            "704/704 - 26s - loss: 0.3559 - accuracy: 0.8722 - val_loss: 2.0057 - val_accuracy: 0.6114\n",
            "Epoch 24/30\n",
            "704/704 - 26s - loss: 0.3349 - accuracy: 0.8815 - val_loss: 4.2266 - val_accuracy: 0.4124\n",
            "Epoch 25/30\n",
            "704/704 - 26s - loss: 0.3229 - accuracy: 0.8848 - val_loss: 3.4193 - val_accuracy: 0.4744\n",
            "Epoch 26/30\n",
            "704/704 - 27s - loss: 0.3013 - accuracy: 0.8909 - val_loss: 2.9410 - val_accuracy: 0.5650\n",
            "Epoch 27/30\n",
            "704/704 - 26s - loss: 0.2875 - accuracy: 0.8978 - val_loss: 1.6758 - val_accuracy: 0.6766\n",
            "Epoch 28/30\n",
            "704/704 - 26s - loss: 0.2693 - accuracy: 0.9031 - val_loss: 1.6908 - val_accuracy: 0.6638\n",
            "Epoch 29/30\n",
            "704/704 - 27s - loss: 0.2600 - accuracy: 0.9064 - val_loss: 2.2048 - val_accuracy: 0.6076\n",
            "Epoch 30/30\n",
            "704/704 - 28s - loss: 0.2482 - accuracy: 0.9117 - val_loss: 3.6035 - val_accuracy: 0.5122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_W_iW3onqop",
        "outputId": "87f9e837-35de-4763-e8b9-6aa81baf3832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#训练30个epoch后，得到的测试集准确率不够，再接着训练10个epoch\n",
        "densenet_121.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = densenet_121.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=10,verbose=2,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "704/704 - 30s - loss: 0.2300 - accuracy: 0.9176 - val_loss: 1.0783 - val_accuracy: 0.7728\n",
            "Epoch 2/10\n",
            "704/704 - 28s - loss: 0.2116 - accuracy: 0.9248 - val_loss: 3.5938 - val_accuracy: 0.5590\n",
            "Epoch 3/10\n",
            "704/704 - 27s - loss: 0.2073 - accuracy: 0.9252 - val_loss: 5.2963 - val_accuracy: 0.3328\n",
            "Epoch 4/10\n",
            "704/704 - 28s - loss: 0.1996 - accuracy: 0.9284 - val_loss: 1.4474 - val_accuracy: 0.7344\n",
            "Epoch 5/10\n",
            "704/704 - 28s - loss: 0.1788 - accuracy: 0.9352 - val_loss: 1.4329 - val_accuracy: 0.7484\n",
            "Epoch 6/10\n",
            "704/704 - 28s - loss: 0.1788 - accuracy: 0.9353 - val_loss: 1.4609 - val_accuracy: 0.7376\n",
            "Epoch 7/10\n",
            "704/704 - 28s - loss: 0.1672 - accuracy: 0.9400 - val_loss: 2.8642 - val_accuracy: 0.5902\n",
            "Epoch 8/10\n",
            "704/704 - 28s - loss: 0.1681 - accuracy: 0.9405 - val_loss: 3.1536 - val_accuracy: 0.5922\n",
            "Epoch 9/10\n",
            "704/704 - 28s - loss: 0.1587 - accuracy: 0.9436 - val_loss: 1.4210 - val_accuracy: 0.7360\n",
            "Epoch 10/10\n",
            "704/704 - 28s - loss: 0.1477 - accuracy: 0.9483 - val_loss: 1.5392 - val_accuracy: 0.7374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9S8bJ6IpS8x",
        "outputId": "1bb7500e-dfe5-4a15-c5c9-3ed69f66488f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#训练30个epoch后，得到的测试集准确率不够，再接着训练10个epoch\n",
        "densenet_121.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = densenet_121.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=10,verbose=2,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "704/704 - 32s - loss: 0.1378 - accuracy: 0.9505 - val_loss: 3.4830 - val_accuracy: 0.5870\n",
            "Epoch 2/10\n",
            "704/704 - 29s - loss: 0.1303 - accuracy: 0.9546 - val_loss: 4.1981 - val_accuracy: 0.5680\n",
            "Epoch 3/10\n",
            "704/704 - 29s - loss: 0.1296 - accuracy: 0.9541 - val_loss: 1.8012 - val_accuracy: 0.7274\n",
            "Epoch 4/10\n",
            "704/704 - 28s - loss: 0.1259 - accuracy: 0.9550 - val_loss: 2.0835 - val_accuracy: 0.6856\n",
            "Epoch 5/10\n",
            "704/704 - 27s - loss: 0.1230 - accuracy: 0.9566 - val_loss: 1.3603 - val_accuracy: 0.7734\n",
            "Epoch 6/10\n",
            "704/704 - 27s - loss: 0.1037 - accuracy: 0.9621 - val_loss: 3.7385 - val_accuracy: 0.5968\n",
            "Epoch 7/10\n",
            "704/704 - 29s - loss: 0.1100 - accuracy: 0.9614 - val_loss: 6.5603 - val_accuracy: 0.4558\n",
            "Epoch 8/10\n",
            "704/704 - 29s - loss: 0.1174 - accuracy: 0.9586 - val_loss: 5.5320 - val_accuracy: 0.4396\n",
            "Epoch 9/10\n",
            "704/704 - 29s - loss: 0.1258 - accuracy: 0.9563 - val_loss: 15.2172 - val_accuracy: 0.1682\n",
            "Epoch 10/10\n",
            "704/704 - 29s - loss: 0.1299 - accuracy: 0.9567 - val_loss: 1.9671 - val_accuracy: 0.7358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXTKRCveI36b",
        "outputId": "1f9d8d1c-324c-455f-adaa-d10035910f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Train densenet_169\n",
        "densenet_169.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = densenet_169.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=50,verbose=2,\n",
        "                    validation_split=0.1)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "704/704 - 41s - loss: 2.1158 - accuracy: 0.2932 - val_loss: 2.2229 - val_accuracy: 0.2460\n",
            "Epoch 2/50\n",
            "704/704 - 38s - loss: 1.7120 - accuracy: 0.3963 - val_loss: 2.4802 - val_accuracy: 0.3126\n",
            "Epoch 3/50\n",
            "704/704 - 37s - loss: 1.5405 - accuracy: 0.4566 - val_loss: 2.5067 - val_accuracy: 0.3146\n",
            "Epoch 4/50\n",
            "704/704 - 37s - loss: 1.3970 - accuracy: 0.5132 - val_loss: 2.5383 - val_accuracy: 0.3010\n",
            "Epoch 5/50\n",
            "704/704 - 37s - loss: 1.2897 - accuracy: 0.5491 - val_loss: 2.2835 - val_accuracy: 0.3202\n",
            "Epoch 6/50\n",
            "704/704 - 38s - loss: 1.1866 - accuracy: 0.5836 - val_loss: 1.8165 - val_accuracy: 0.4212\n",
            "Epoch 7/50\n",
            "704/704 - 38s - loss: 1.1066 - accuracy: 0.6158 - val_loss: 2.2554 - val_accuracy: 0.4296\n",
            "Epoch 8/50\n",
            "704/704 - 39s - loss: 1.0242 - accuracy: 0.6403 - val_loss: 2.8961 - val_accuracy: 0.2856\n",
            "Epoch 9/50\n",
            "704/704 - 38s - loss: 0.9581 - accuracy: 0.6674 - val_loss: 6.3813 - val_accuracy: 0.1528\n",
            "Epoch 10/50\n",
            "704/704 - 38s - loss: 0.9012 - accuracy: 0.6880 - val_loss: 2.7654 - val_accuracy: 0.3024\n",
            "Epoch 11/50\n",
            "704/704 - 39s - loss: 0.8454 - accuracy: 0.7089 - val_loss: 1.3764 - val_accuracy: 0.6002\n",
            "Epoch 12/50\n",
            "704/704 - 38s - loss: 0.7935 - accuracy: 0.7252 - val_loss: 4.6614 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "704/704 - 37s - loss: 0.7576 - accuracy: 0.7381 - val_loss: 1.4697 - val_accuracy: 0.5740\n",
            "Epoch 14/50\n",
            "704/704 - 38s - loss: 0.7062 - accuracy: 0.7533 - val_loss: 1.2282 - val_accuracy: 0.6642\n",
            "Epoch 15/50\n",
            "704/704 - 39s - loss: 0.6704 - accuracy: 0.7646 - val_loss: 2.4010 - val_accuracy: 0.4556\n",
            "Epoch 16/50\n",
            "704/704 - 39s - loss: 0.6407 - accuracy: 0.7765 - val_loss: 1.8476 - val_accuracy: 0.5596\n",
            "Epoch 17/50\n",
            "704/704 - 38s - loss: 0.6115 - accuracy: 0.7850 - val_loss: 2.8796 - val_accuracy: 0.5124\n",
            "Epoch 18/50\n",
            "704/704 - 39s - loss: 0.5768 - accuracy: 0.7999 - val_loss: 1.5898 - val_accuracy: 0.6270\n",
            "Epoch 19/50\n",
            "704/704 - 39s - loss: 0.5453 - accuracy: 0.8094 - val_loss: 2.5592 - val_accuracy: 0.5058\n",
            "Epoch 20/50\n",
            "704/704 - 38s - loss: 0.5305 - accuracy: 0.8152 - val_loss: 2.7501 - val_accuracy: 0.3770\n",
            "Epoch 21/50\n",
            "704/704 - 38s - loss: 0.4992 - accuracy: 0.8246 - val_loss: 1.7904 - val_accuracy: 0.6200\n",
            "Epoch 22/50\n",
            "704/704 - 40s - loss: 0.4679 - accuracy: 0.8358 - val_loss: 1.5474 - val_accuracy: 0.6622\n",
            "Epoch 23/50\n",
            "704/704 - 40s - loss: 0.4436 - accuracy: 0.8447 - val_loss: 2.1194 - val_accuracy: 0.5480\n",
            "Epoch 24/50\n",
            "704/704 - 40s - loss: 0.4272 - accuracy: 0.8494 - val_loss: 1.4407 - val_accuracy: 0.6640\n",
            "Epoch 25/50\n",
            "704/704 - 39s - loss: 0.4130 - accuracy: 0.8554 - val_loss: 3.5708 - val_accuracy: 0.4204\n",
            "Epoch 26/50\n",
            "704/704 - 39s - loss: 0.3828 - accuracy: 0.8657 - val_loss: 1.9803 - val_accuracy: 0.6278\n",
            "Epoch 27/50\n",
            "704/704 - 40s - loss: 0.3522 - accuracy: 0.8751 - val_loss: 2.7392 - val_accuracy: 0.5368\n",
            "Epoch 28/50\n",
            "704/704 - 39s - loss: 0.3342 - accuracy: 0.8818 - val_loss: 7.1771 - val_accuracy: 0.3366\n",
            "Epoch 29/50\n",
            "704/704 - 39s - loss: 0.3175 - accuracy: 0.8879 - val_loss: 1.3173 - val_accuracy: 0.7344\n",
            "Epoch 30/50\n",
            "704/704 - 39s - loss: 0.2963 - accuracy: 0.8961 - val_loss: 7.0904 - val_accuracy: 0.3858\n",
            "Epoch 31/50\n",
            "704/704 - 39s - loss: 0.2969 - accuracy: 0.8977 - val_loss: 2.7425 - val_accuracy: 0.5532\n",
            "Epoch 32/50\n",
            "704/704 - 39s - loss: 0.2670 - accuracy: 0.9054 - val_loss: 1.3047 - val_accuracy: 0.7432\n",
            "Epoch 33/50\n",
            "704/704 - 39s - loss: 0.2488 - accuracy: 0.9118 - val_loss: 5.2684 - val_accuracy: 0.4026\n",
            "Epoch 34/50\n",
            "704/704 - 38s - loss: 0.2588 - accuracy: 0.9076 - val_loss: 1.6290 - val_accuracy: 0.7120\n",
            "Epoch 35/50\n",
            "704/704 - 39s - loss: 0.2391 - accuracy: 0.9177 - val_loss: 2.8537 - val_accuracy: 0.5306\n",
            "Epoch 36/50\n",
            "704/704 - 38s - loss: 0.2196 - accuracy: 0.9214 - val_loss: 2.7424 - val_accuracy: 0.5952\n",
            "Epoch 37/50\n",
            "704/704 - 38s - loss: 0.1993 - accuracy: 0.9286 - val_loss: 3.3078 - val_accuracy: 0.6060\n",
            "Epoch 38/50\n",
            "704/704 - 38s - loss: 0.1976 - accuracy: 0.9293 - val_loss: 3.4135 - val_accuracy: 0.5872\n",
            "Epoch 39/50\n",
            "704/704 - 38s - loss: 0.1808 - accuracy: 0.9359 - val_loss: 9.8669 - val_accuracy: 0.2794\n",
            "Epoch 40/50\n",
            "704/704 - 38s - loss: 0.1817 - accuracy: 0.9367 - val_loss: 1.6064 - val_accuracy: 0.7376\n",
            "Epoch 41/50\n",
            "704/704 - 38s - loss: 0.1607 - accuracy: 0.9433 - val_loss: 3.7463 - val_accuracy: 0.5532\n",
            "Epoch 42/50\n",
            "704/704 - 38s - loss: 0.1577 - accuracy: 0.9446 - val_loss: 6.3860 - val_accuracy: 0.4546\n",
            "Epoch 43/50\n",
            "704/704 - 39s - loss: 0.1546 - accuracy: 0.9452 - val_loss: 1.6975 - val_accuracy: 0.7348\n",
            "Epoch 44/50\n",
            "704/704 - 38s - loss: 0.1441 - accuracy: 0.9489 - val_loss: 2.2376 - val_accuracy: 0.6712\n",
            "Epoch 45/50\n",
            "704/704 - 38s - loss: 0.1442 - accuracy: 0.9498 - val_loss: 8.2398 - val_accuracy: 0.4042\n",
            "Epoch 46/50\n",
            "704/704 - 38s - loss: 0.1510 - accuracy: 0.9481 - val_loss: 1.4742 - val_accuracy: 0.7650\n",
            "Epoch 47/50\n",
            "704/704 - 38s - loss: 0.1115 - accuracy: 0.9596 - val_loss: 4.7824 - val_accuracy: 0.5452\n",
            "Epoch 48/50\n",
            "704/704 - 38s - loss: 0.1262 - accuracy: 0.9551 - val_loss: 2.5630 - val_accuracy: 0.6616\n",
            "Epoch 49/50\n",
            "704/704 - 38s - loss: 0.1137 - accuracy: 0.9593 - val_loss: 1.5265 - val_accuracy: 0.7662\n",
            "Epoch 50/50\n",
            "704/704 - 40s - loss: 0.1003 - accuracy: 0.9649 - val_loss: 1.6507 - val_accuracy: 0.7582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3pIZ-XYI36g"
      },
      "source": [
        "### 4.2 Test your models. (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viH2rEf6I36Z",
        "outputId": "c4d1d9f5-5b4e-4f39-b04f-09022e43f08c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# implement your code here.\n",
        "#test densenet_121 \n",
        "loss,accuracy = densenet_121.evaluate(x_test,y_test,verbose=2)\n",
        "print('test loss',loss)\n",
        "print('test accuracy',accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 3s - loss: 1.9614 - accuracy: 0.7277\n",
            "test loss 1.9614012241363525\n",
            "test accuracy 0.7276999950408936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S-1l9X5I36j",
        "outputId": "d2e93480-6667-4495-9610-5c22dcf7f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#test densenet_169 \n",
        "loss,accuracy = densenet_169.evaluate(x_test,y_test,verbose=2)\n",
        "print('test loss',loss)\n",
        "print('test accuracy',accuracy)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 5s - loss: 1.7371 - accuracy: 0.7418\n",
            "test loss 1.737108826637268\n",
            "test accuracy 0.7418000102043152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSemnBuZI36l"
      },
      "source": [
        "---\n",
        "## 5. Load the pre-trained models from Keras and evaluate them. (15 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0s4qVfACI36m",
        "outputId": "87887fac-3cdc-4505-b152-04e879f0cbfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "base_model = DenseNet121(include_top=False,weights='imagenet',input_shape=(32,32,3))\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) \n",
        "predictions = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)(x)\n",
        "dense121_model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "dense121_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = dense121_model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=30,\n",
        "                    validation_split=0.1)\n",
        "# implement your code here."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 27s 39ms/step - loss: 1.0143 - accuracy: 0.6541 - val_loss: 0.8309 - val_accuracy: 0.7164\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.5686 - accuracy: 0.8021 - val_loss: 0.8126 - val_accuracy: 0.7214\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.4091 - accuracy: 0.8576 - val_loss: 0.6574 - val_accuracy: 0.7922\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.3020 - accuracy: 0.8958 - val_loss: 1.0350 - val_accuracy: 0.6888\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.2313 - accuracy: 0.9189 - val_loss: 0.6851 - val_accuracy: 0.7888\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.1778 - accuracy: 0.9392 - val_loss: 0.7114 - val_accuracy: 0.7974\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.1313 - accuracy: 0.9544 - val_loss: 1.4399 - val_accuracy: 0.6076\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.1376 - accuracy: 0.9523 - val_loss: 1.1270 - val_accuracy: 0.7004\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.1062 - accuracy: 0.9629 - val_loss: 1.2360 - val_accuracy: 0.7016\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 26s 36ms/step - loss: 0.0786 - accuracy: 0.9732 - val_loss: 2.0491 - val_accuracy: 0.5838\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 26s 36ms/step - loss: 0.0903 - accuracy: 0.9690 - val_loss: 1.6374 - val_accuracy: 0.6290\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.0769 - accuracy: 0.9738 - val_loss: 1.1871 - val_accuracy: 0.7370\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.0601 - accuracy: 0.9795 - val_loss: 1.0690 - val_accuracy: 0.7616\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 1.6859 - val_accuracy: 0.6658\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.0553 - accuracy: 0.9819 - val_loss: 0.7579 - val_accuracy: 0.8294\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 1.1501 - val_accuracy: 0.7484\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 1.4014 - val_accuracy: 0.7182\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.0528 - accuracy: 0.9819 - val_loss: 0.8760 - val_accuracy: 0.8090\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 0.9377 - val_accuracy: 0.7986\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.6915 - val_accuracy: 0.8510\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 1.0198 - val_accuracy: 0.8040\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 1.5971 - val_accuracy: 0.7128\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 1.7118 - val_accuracy: 0.7054\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.7109 - val_accuracy: 0.8486\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 1.3003 - val_accuracy: 0.7518\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 2.2677 - val_accuracy: 0.6072\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 0.8278 - val_accuracy: 0.8340\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 1.4696 - val_accuracy: 0.7138\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 3.1387 - val_accuracy: 0.4800\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.7176 - val_accuracy: 0.8474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR_f3eGe1GVQ",
        "outputId": "0e0c52db-8b23-4328-c676-3113fc76f4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "base_model = DenseNet121(include_top=False,weights=None,input_shape=(32,32,3))\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) \n",
        "predictions = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)(x)\n",
        "dense121_model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "dense121_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = dense121_model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=30,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "704/704 [==============================] - 28s 40ms/step - loss: 1.7320 - accuracy: 0.3690 - val_loss: 2.2091 - val_accuracy: 0.2916\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 26s 36ms/step - loss: 1.4156 - accuracy: 0.4848 - val_loss: 4.0346 - val_accuracy: 0.1794\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 1.2589 - accuracy: 0.5443 - val_loss: 1.6501 - val_accuracy: 0.4158\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 1.1331 - accuracy: 0.5937 - val_loss: 1.6426 - val_accuracy: 0.4726\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 26s 36ms/step - loss: 1.0317 - accuracy: 0.6291 - val_loss: 2.8876 - val_accuracy: 0.3180\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 25s 36ms/step - loss: 0.9458 - accuracy: 0.6647 - val_loss: 3.6982 - val_accuracy: 0.2486\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.8516 - accuracy: 0.6974 - val_loss: 1.9375 - val_accuracy: 0.4306\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.7699 - accuracy: 0.7274 - val_loss: 2.0009 - val_accuracy: 0.4236\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.6909 - accuracy: 0.7549 - val_loss: 1.2578 - val_accuracy: 0.5902\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.6149 - accuracy: 0.7838 - val_loss: 1.3285 - val_accuracy: 0.5790\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.5456 - accuracy: 0.8074 - val_loss: 1.8651 - val_accuracy: 0.4710\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.4860 - accuracy: 0.8302 - val_loss: 1.7954 - val_accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.4193 - accuracy: 0.8524 - val_loss: 1.8088 - val_accuracy: 0.4868\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.3710 - accuracy: 0.8713 - val_loss: 2.5901 - val_accuracy: 0.4526\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.3165 - accuracy: 0.8899 - val_loss: 1.9257 - val_accuracy: 0.4972\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.2798 - accuracy: 0.9019 - val_loss: 2.2198 - val_accuracy: 0.5088\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 25s 35ms/step - loss: 0.2523 - accuracy: 0.9118 - val_loss: 5.1016 - val_accuracy: 0.3120\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.2203 - accuracy: 0.9231 - val_loss: 2.9611 - val_accuracy: 0.4316\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 24s 35ms/step - loss: 0.1892 - accuracy: 0.9350 - val_loss: 3.3118 - val_accuracy: 0.4128\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1863 - accuracy: 0.9364 - val_loss: 2.4290 - val_accuracy: 0.5066\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1756 - accuracy: 0.9384 - val_loss: 2.3361 - val_accuracy: 0.5118\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1411 - accuracy: 0.9518 - val_loss: 3.0305 - val_accuracy: 0.4588\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1340 - accuracy: 0.9543 - val_loss: 3.1224 - val_accuracy: 0.4086\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1194 - accuracy: 0.9592 - val_loss: 2.8146 - val_accuracy: 0.5174\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1123 - accuracy: 0.9620 - val_loss: 3.6520 - val_accuracy: 0.3888\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.1212 - accuracy: 0.9590 - val_loss: 2.0741 - val_accuracy: 0.5812\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0818 - accuracy: 0.9727 - val_loss: 1.6392 - val_accuracy: 0.6544\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 3.2385 - val_accuracy: 0.4326\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0787 - accuracy: 0.9730 - val_loss: 4.9328 - val_accuracy: 0.3482\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 24s 34ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 3.1819 - val_accuracy: 0.4978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "6YxGXxNuI36q",
        "outputId": "977b1778-eeba-4cec-afa0-0134716a1211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#不使用imagenet预训练权重模型的结果\n",
        "loss,accuracy = dense121_model.evaluate(x_test,y_test,verbose=2)\n",
        "print('test loss',loss)\n",
        "print('test accuracy',accuracy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 3s - loss: 3.2058 - accuracy: 0.4898\n",
            "test loss 3.2058067321777344\n",
            "test accuracy 0.48980000615119934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tdzbv8kkKAA",
        "outputId": "186d191a-8ceb-4974-f3fe-2c5ba066c64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#使用imagenet预训练模型权重\n",
        "loss,accuracy = dense121_model.evaluate(x_test,y_test,verbose=2)\n",
        "print('test loss',loss)\n",
        "print('test accuracy',accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 3s - loss: 0.7618 - accuracy: 0.8437\n",
            "test loss 0.7617789506912231\n",
            "test accuracy 0.8436999917030334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noqj5VnwI36s",
        "outputId": "69fd4d55-ddc1-4a0a-83f9-e9f7008c4089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model = DenseNet169(include_top=False,weights='imagenet',input_shape=(32,32,3))\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) \n",
        "predictions = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)(x)\n",
        "dense169_model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "dense169_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = dense169_model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=30,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "loss,accuracy = dense169_model.evaluate(x_test,y_test,verbose=2)\n",
        "print('test loss',loss)\n",
        "print('test accuracy',accuracy)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "704/704 [==============================] - 37s 53ms/step - loss: 0.9751 - accuracy: 0.6636 - val_loss: 1.1039 - val_accuracy: 0.6404\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 34s 49ms/step - loss: 0.5332 - accuracy: 0.8148 - val_loss: 0.9029 - val_accuracy: 0.7014\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 34s 48ms/step - loss: 0.3646 - accuracy: 0.8741 - val_loss: 0.6474 - val_accuracy: 0.7946\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 33s 48ms/step - loss: 0.2473 - accuracy: 0.9150 - val_loss: 0.6929 - val_accuracy: 0.7882\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 34s 48ms/step - loss: 0.1763 - accuracy: 0.9402 - val_loss: 1.3457 - val_accuracy: 0.7020\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.1322 - accuracy: 0.9550 - val_loss: 0.9970 - val_accuracy: 0.7228\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0925 - accuracy: 0.9689 - val_loss: 0.7198 - val_accuracy: 0.8198\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0701 - accuracy: 0.9767 - val_loss: 1.3018 - val_accuracy: 0.7124\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 18.8165 - val_accuracy: 0.1290\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.1805 - accuracy: 0.9378 - val_loss: 0.9491 - val_accuracy: 0.7684\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.8140 - val_accuracy: 0.8154\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.7127 - val_accuracy: 0.8272\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.9446 - val_accuracy: 0.7960\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.6937 - val_accuracy: 0.8440\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.0510 - val_accuracy: 0.7838\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 6.1746 - val_accuracy: 0.2684\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0700 - accuracy: 0.9763 - val_loss: 1.4895 - val_accuracy: 0.6804\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0414 - accuracy: 0.9864 - val_loss: 0.6568 - val_accuracy: 0.8546\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 1.7825 - val_accuracy: 0.6966\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 1.2202 - val_accuracy: 0.7572\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 1.5379 - val_accuracy: 0.6952\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 1.4612 - val_accuracy: 0.7320\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.7533 - val_accuracy: 0.8460\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 4.2391 - val_accuracy: 0.3942\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 2.5521 - val_accuracy: 0.5990\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.8608 - val_accuracy: 0.8270\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 2.0415 - val_accuracy: 0.6268\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.7073 - val_accuracy: 0.8570\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 2.5056 - val_accuracy: 0.6352\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 33s 47ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.7332 - val_accuracy: 0.8544\n",
            "313/313 - 4s - loss: 0.7747 - accuracy: 0.8483\n",
            "test loss 0.7747172117233276\n",
            "test accuracy 0.8482999801635742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09o_ZlHOI36u"
      },
      "source": [
        "---\n",
        "## 6. Analysis your results. (20 marks)\n",
        "Compare the performance of your models with the following analysis. Both English and Chinese answers are acceptable.\n",
        "1. Is your implementation of DenseNet-169 better than DenseNet-121? If yes, how is the improvement? If no, try to figure the reason out based on your experiments. (10 marks)\n",
        "\n",
        "Answer: DenseNet-169模型表现的更好。在学习率等超参保持一致的情况下，两个模型训练50个epoch后，DenseNet-169在测试集上的准确率为74.2%,DenseNet-121的准确率为72.8%。测试集的准确率提高了。\n",
        "\n",
        "2. Compare the results of your implementation with the pre-trained models from Keras. (10 marks)\n",
        "\n",
        "Answer: 预训练模型网络训练的更快，在训练完第一个epoch后loss为0.98，准确率为66%。因为预训练模型中参数使用的是在imagenet中训练好的参数，而我们自定义模型中参数是随机初始化的。最后在训练完30个epoch后也表现的最好，测试集准确率为84%。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ayC977I36v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}