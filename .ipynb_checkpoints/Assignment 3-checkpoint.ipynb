{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Character-Level Recurrent Neural Network by PyTorch\n",
    "\n",
    "In this assignment, you are required to implement Character-Level RNN just as we have learned in the class. However, the difference is we use another dataset in this assignment.\n",
    "\n",
    "Read through the tutorial [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) that builds a char-rnn that is used to classify names by their country of origin, which is introduced in the class. It is recommended that you can reproduce the tutorial’s results on the provided name dataset before moving on (notebook for Lecture 7), since the neural network architectures remain largely the same. Make sure you try your best to understand the dimensions of each layer (e.g. which ones can stay the same, and which are hyperparameters for us to tweak).\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Code implementation. (20 marks)\n",
    "2. Experimentation and analysis (80 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNS4OZXxMZ-A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Download and unzip files\n",
    "# !pip3 install scikit-learn\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_test.txt\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_val.zip\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_train.zip\n",
    "# !sudo apt-get install unzip\n",
    "# !unzip cities_val.zip \n",
    "# !unzip cities_train.zip \n",
    "# from os.path import exists\n",
    "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "#!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "# !pip3 install torch torchvision\n",
    "  \n",
    "import torch\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIJxbqMDNTTl"
   },
   "outputs": [],
   "source": [
    "#Verfiy file download\n",
    "# !head train/af.txt\n",
    "# !printf \"\\n\"\n",
    "# !head val/af.txt\n",
    "# !printf \"\\n\"\n",
    "# !head cities_test.txt\n",
    "# !printf \"\\n\"\n",
    "#Verify CUDA acceleration should print cuda:0\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation (20 marks)\n",
    "\n",
    "**You should implement all the following functions and you are not allowed to delete any of them. Of course you can add more functions based on this skeleton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwB5RzvfOGr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: train/af.txt\n",
      "reading file: train/cn.txt\n",
      "reading file: train/de.txt\n",
      "reading file: train/fi.txt\n",
      "reading file: train/fr.txt\n",
      "reading file: train/in.txt\n",
      "reading file: train/ir.txt\n",
      "reading file: train/pk.txt\n",
      "reading file: train/za.txt\n",
      "reading file: val/af.txt\n",
      "reading file: val/cn.txt\n",
      "reading file: val/de.txt\n",
      "reading file: val/fi.txt\n",
      "reading file: val/fr.txt\n",
      "reading file: val/in.txt\n",
      "reading file: val/ir.txt\n",
      "reading file: val/pk.txt\n",
      "reading file: val/za.txt\n"
     ]
    }
   ],
   "source": [
    "#main_classify.py\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import unicodedata\n",
    "from io import open\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "Don't change these constants for the classification task.\n",
    "You may use different copies for the sentence generation model.\n",
    "'''\n",
    "languages = [\"af\", \"cn\", \"de\", \"fi\", \"fr\", \"in\", \"ir\", \"pk\", \"za\"]\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "n_languages = len(languages)\n",
    "\n",
    "'''\n",
    "Returns the words of the language specified by reading it from the data folder\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "Return: A nx1 array containing the words of the specified language\n",
    "'''\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def getWords(baseDir, lang, train = True):\n",
    "    if train:\n",
    "        baseDir = baseDir + 'train'\n",
    "    else:\n",
    "        baseDir = baseDir + 'val'\n",
    "    filename = baseDir +'/' + lang + '.txt'\n",
    "    print(\"reading file:\",filename)\n",
    "    #Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）\n",
    "    words = open(filename,encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(word) for word in words]\n",
    "\n",
    "#test getWords\n",
    "# words = getWords('',languages[0])\n",
    "# print(words)\n",
    "\n",
    "'''\n",
    "Returns a label corresponding to the language\n",
    "For example it returns an array of 0s for af\n",
    "Return: A nx1 array as integers containing index of the specified language in the \"languages\" array\n",
    "'''\n",
    "def getLabels(lang, length):\n",
    "    index = languages.index(lang)\n",
    "    labels = np.zeros(length)\n",
    "    labels[index] = 1\n",
    "    \n",
    "#     labels = [index]\n",
    "    return labels\n",
    "\n",
    "#test getLabels\n",
    "# labels = getLabels(languages[0], len(languages))\n",
    "# print(labels)#[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "\n",
    "'''\n",
    "Returns all the laguages and labels after reading it from the file\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "You may assume that the files exist in baseDir and have the same names.\n",
    "Return: X, y where X is nx1 and y is nx1\n",
    "'''\n",
    "def readData(baseDir, train=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0,len(languages)):\n",
    "        X.append(getWords(baseDir,languages[i],train))\n",
    "        y.append(languages[i])\n",
    "    return X,y\n",
    "#test  readData\n",
    "\n",
    "train_X,train_y = readData('')\n",
    "val_X,val_y = readData('',False)\n",
    "\n",
    "# print(len(X))\n",
    "# print(len(y))\n",
    "# print(X[0])\n",
    "# print(y[0])\n",
    "\n",
    "'''\n",
    "Convert a line/word to a pytorch tensor of numbers\n",
    "Refer the tutorial in the spec\n",
    "Return: A tensor corresponding to the given line\n",
    "'''\n",
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line),1,n_letters)\n",
    "    for li,letter in enumerate(line):\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "#test line_to_tensor\n",
    "# tensor = line_to_tensor(\"Yang\")\n",
    "# print(tensor)\n",
    "# print(tensor.shape) #[4, 1, 57]\n",
    "\n",
    "'''\n",
    "Returns the category/class of the output from the neural network\n",
    "Input: Output of the neural networks (class probabilities)\n",
    "Return: A tuple with (language, language_index)\n",
    "        language: \"af\", \"cn\", etc.\n",
    "        language_index: 0, 1, etc.\n",
    "'''\n",
    "def category_from_output(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "#     print(\"top_n\",top_n)\n",
    "#     print(\"top_i\",top_i)\n",
    "    language_i = top_i[0].item()\n",
    "    return languages[language_i], language_i\n",
    "\n",
    "'''\n",
    "Get a random input output pair to be used for training \n",
    "Refer the tutorial in the spec\n",
    "'''\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def random_training_pair(X, y):\n",
    "    language = randomChoice(y)\n",
    "    language_index = y.index(language)\n",
    "    line = randomChoice(X[language_index])\n",
    "    language_tensor = torch.tensor([language_index],dtype=torch.long)\n",
    "    line_tensor = line_to_tensor(line)\n",
    "    return language,line ,language_tensor,line_tensor\n",
    "    \n",
    "#test random_training_pair\n",
    "# language,line ,language_tensor,line_tensor = random_training_pair(train_X,train_y)\n",
    "# print(language)\n",
    "# print(line)\n",
    "# print(language_tensor)\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: a list of class labels as integers\n",
    "'''\n",
    "#输入：X是要预测的字符串，y是对应的标签\n",
    "#输出：预测得到的前三个最高的类别\n",
    "def predict(model, X, y):\n",
    "    \n",
    "    line_tensor = line_to_tensor(X)\n",
    "    language_tensor = torch.tensor([languages.index(y)],dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden()\n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = model(line_tensor[i], hidden)\n",
    "\n",
    "        language, language_index = category_from_output(output)\n",
    "    \n",
    "    return language\n",
    "\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: The accuracy of the given model on the given input X and target y\n",
    "'''\n",
    "def calculateAccuracy(model, X, y):\n",
    "    count = 0\n",
    "    num = 0\n",
    "    for i in range(0,len(y)):\n",
    "        num += len(X[i])\n",
    "        for j in range(0,len(X[i])):\n",
    "            language = predict(model,X[i][j],y[i])\n",
    "            if (language == y[i]):\n",
    "                count+=1\n",
    "    acc = count/num\n",
    "    print('There is %s samples,Accuracy=%s'%(num,acc))\n",
    "    return acc\n",
    "\n",
    "'''\n",
    "Train the model for one epoch/one training word.\n",
    "Ensure that it runs within 3 seconds.\n",
    "Input: X and y are lists of words as strings and classes as integers respectively\n",
    "Returns: You may return anything\n",
    "'''\n",
    "def trainOneEpoch(model, criterion, optimizer, X, y):\n",
    "    \n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = model(X[i], hidden)\n",
    "        \n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "'''\n",
    "Use this to train and save your classification model. \n",
    "Save your model with the filename \"model_classify\"\n",
    "'''\n",
    "def run(model,criterion):\n",
    "    n_iters = 100000\n",
    "    print_every = 5000\n",
    "    plot_every = 1000\n",
    "    \n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    \n",
    "    learning_rate = 0.005 \n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        language,line,language_tensor,line_tensor = random_training_pair(train_X,train_y)\n",
    "        #trainOneEpoch(model, criterion, optimizer, X, y)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "        output, loss = trainOneEpoch(model,criterion,optimizer,line_tensor,language_tensor)\n",
    "        current_loss += loss\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = category_from_output(output)\n",
    "            correct = '✓' if guess == language else '✗ (%s)' % language\n",
    "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, \\\n",
    "                                    timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "    torch.save(model,'model_classify.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbOusBLKPsrx"
   },
   "outputs": [],
   "source": [
    "#models.py\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "Please add default values for all the parameters of __init__.\n",
    "'''\n",
    "class CharRNNClassify(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNNClassify, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)  \n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)  \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        combined = torch.cat((input,hidden),1)\n",
    "        hidden = self.i2h(combined)\n",
    "        hidden = self.tanh(hidden)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "criterion = nn.NLLLoss()\n",
    "CharRnn = CharRNNClassify(n_letters, n_hidden, len(languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 14s) 2.0834 sitio izair j. da oliveira / fi ✗ (za)\n",
      "10000 10% (0m 29s) 2.6496 klemes / fr ✗ (fi)\n",
      "15000 15% (0m 44s) 0.4051 tezebazar / za ✓\n",
      "20000 20% (0m 58s) 3.6696 sumberpinang barat / af ✗ (in)\n",
      "25000 25% (1m 13s) 3.2178 liren / fr ✗ (cn)\n",
      "30000 30% (1m 27s) 0.3968 saintmardsdeblacarville / fr ✓\n",
      "35000 35% (1m 42s) 5.0742 chung / cn ✗ (pk)\n",
      "40000 40% (1m 57s) 3.5330 kafr al hinnawi / fi ✗ (af)\n",
      "45000 45% (2m 12s) 1.2742 qog ondor xiang / cn ✓\n",
      "50000 50% (2m 26s) 2.2187 dechret doukkane / in ✗ (de)\n",
      "55000 55% (2m 41s) 0.8410 hof wendorf / de ✓\n",
      "60000 60% (2m 56s) 1.7670 la candelarita / ir ✗ (de)\n",
      "65000 65% (3m 10s) 0.6145 nanyueh / cn ✓\n",
      "70000 70% (3m 25s) 0.0734 veauvillelesquelles / fr ✓\n",
      "75000 75% (3m 40s) 0.1101 kharlanwala / pk ✓\n",
      "80000 80% (3m 55s) 0.8211 mosouwan / cn ✓\n",
      "85000 85% (4m 10s) 0.2821 ghulam haidar khanwala / pk ✓\n",
      "90000 90% (4m 24s) 1.3015 zaur muhammad khan / af ✗ (pk)\n",
      "95000 95% (4m 39s) 1.5904 trojes de aguirre / fr ✗ (ir)\n",
      "100000 100% (4m 53s) 0.4812 le village / fr ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CharRNNClassify. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "run(CharRnn,criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation and Analysis (80 marks)\n",
    "\n",
    "Complete the following analysis on the city names dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code to output accuracy on the validation set (10 marks).  Use a confusion matrix plot to support your answer (10 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is %s samples,Accuracy=%s 27000 0.5212962962962963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5212962962962963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateAccuracy(CharRnn, train_X, train_y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 900 samples,Accuracy=0.48777777777777775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48777777777777775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateAccuracy(CharRnn, val_X, val_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "confusion = torch.zeros(len(languages), len(languages))\n",
    "\n",
    "for i in range(0,len(val_y)):\n",
    "    for j in range(0,len(val_X[i])):\n",
    "        guess = predict(CharRnn,val_X[i][j],val_y[i])\n",
    "        language_i = languages.index(val_y[i])\n",
    "        guess_i = languages.index(guess)\n",
    "        confusion[language_i][guess_i] += 1\n",
    "                \n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + languages, rotation=90)\n",
    "ax.set_yticklabels([''] + languages)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Periodically compute the loss on the validation set, and create a plot with the training and validation loss as training progresses (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Experiment with the learning rate. You can try a few different learning rates and observe how this affects the loss. Another common practice is to drop the learning rate when the loss has plateaued. Use plots to explain your experiments and their effects on the loss (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Experiment with the size of the hidden layer or the model architecture How does this affect validation accuracy (20 marks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw6_skeleton.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
