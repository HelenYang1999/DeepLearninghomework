{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: DenseNet with CIFAR10 Dataset by TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are required to implement DenseNet to classify images from the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) by using TensorFlow with Keras. DenseNet is very well-known and therefore it has been implemented and pre-trained by Keras. You are also required to load and test the pre-trained models, and compare them with your models.\n",
    "\n",
    "First of all, read the DenseNet paper. DenseNet was originally proposed in 2016 by Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger in the following paper:\n",
    "https://arxiv.org/abs/1608.06993\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Answer a short question about DenseNet. (10 marks)\n",
    "2. Load and visualize the data.\n",
    "3. Implement your models. (30 marks)\n",
    "4. Train and evaluate your models. (25 marks)\n",
    "5. Load the pre-trained models from Keras and evaluate them. (15 marks)\n",
    "6. Analysis your results. (20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Answer a short question (20 marks)\n",
    "\n",
    "Now that you know what DenseNet is all about, let's compare it to VGG.\n",
    "Both VGG and DenseNet papers describe several variations of their models that differ by their depth.\n",
    "For example, VGG16 and VGG19, DenseNet-121 and DenseNet-169 are four examples from these papers.\n",
    "\n",
    "Aside from difference in network depth, how is the architecture of DenseNet different from that of VGG? Please enter your answer in the next cell (approximately 100-200 words, both English and Chinese are acceptable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG网络是基于AlexNet的改进，主要思想是用多个小卷积核来代替一个大卷积核，使网络结构变得\n",
    "复杂，学到更多信息的同时参数变得更少，网络变得更有效率。DenseNet主要是基于ResNet的改进，通过对特征图的重用，达到更浅的网络、更少的参数、更好的性能。DenseNet在设计网络的时候，也借鉴了VGG的结构，卷积层主要使用的是3×3的小卷积核。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load and visualize the data.\n",
    "\n",
    "The data is directly loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# load the CIFAR10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# input image dimensions\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# mormalize data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(y_train[0])\n",
    "# convert class vectors to binary class matrices.\n",
    "#独热编码，将6转换成[0,0,0,0,0,0,1,0,0,0]\n",
    "# y_train = to_categorical(y_train, num_classes)\n",
    "# print('y_train shape:', y_train.shape)\n",
    "# print(y_train[0])\n",
    "from tensorflow.keras.datasets import cifar10from tensorflow.keras.datasets import cifar10# y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.reshape((50000, 32, 32, 3)).astype('float32') / 255\n",
    "x_test = x_test.reshape((10000, 32, 32, 3)).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2358a882ec8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Implement your models (30 marks)\n",
    "\n",
    "In this task, you are required to implement DenseNet-121 and DenseNet-169 as depicted in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_block (DenseBlock)     multiple                  339264    \n",
      "_________________________________________________________________\n",
      "transition_layer (Transition multiple                  33920     \n",
      "_________________________________________________________________\n",
      "dense_block_1 (DenseBlock)   multiple                  931968    \n",
      "_________________________________________________________________\n",
      "transition_layer_1 (Transiti multiple                  133376    \n",
      "_________________________________________________________________\n",
      "dense_block_2 (DenseBlock)   multiple                  2877696   \n",
      "_________________________________________________________________\n",
      "transition_layer_2 (Transiti multiple                  528896    \n",
      "_________________________________________________________________\n",
      "dense_block_3 (DenseBlock)   multiple                  2188800   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  10250     \n",
      "=================================================================\n",
      "Total params: 7,053,898\n",
      "Trainable params: 6,972,298\n",
      "Non-trainable params: 81,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the code of your DenseNet-121 model here.\n",
    "#https://keras.io/zh/layers/convolutional/\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#https://keras.io/zh/layers/writing-your-own-keras-layers/  Keras2.0needed\n",
    "#2.2.4-tf Satisfied\n",
    "\n",
    "# 瓶颈层，相当于每一个稠密块中若干个相同的H函数\n",
    "class BottleNeck(layers.Layer):\n",
    "    # growth_rate对应的是论文中的增长率k，指经过一个BottleNet输出的特征图的通道数；drop_rate指失活率。\n",
    "    def __init__(self, growth_rate, drop_rate):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv1 = layers.Conv2D(filters=4 * growth_rate,  # 使用1*1卷积核将通道数降维到4*k\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters=growth_rate,  # 使用3*3卷积核，使得输出维度（通道数）为k\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.dropout = layers.Dropout(rate=drop_rate)\n",
    "        # 将网络层存入一个列表中\n",
    "        self.listLayers = [self.bn1,\n",
    "                           self.relu,\n",
    "                           self.conv1,\n",
    "                           self.bn2,\n",
    "                           self.relu,\n",
    "                           self.conv2,\n",
    "                           self.dropout]\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.listLayers.layers:\n",
    "            y = layer(y)\n",
    "        # 每经过一个BottleNet，将输入和输出按通道连结。作用是：将前l层的输入连结起来，作为下一个BottleNet的输入。\n",
    "        y = layers.concatenate([x, y], axis=-1)\n",
    "        return y\n",
    "\n",
    "# 稠密块，由若干个相同的瓶颈层构成\n",
    "class DenseBlock(layers.Layer):\n",
    "    # num_layers表示该稠密块存在BottleNet的个数，也就是一个稠密块的层数L\n",
    "    def __init__(self, num_layers, growth_rate, drop_rate=0.5):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.growth_rate = growth_rate\n",
    "        self.drop_rate = drop_rate\n",
    "        self.listLayers = []\n",
    "        # 一个DenseBlock由多个相同的BottleNeck构成，我们将它们放入一个列表中。\n",
    "        for _ in range(num_layers):\n",
    "            self.listLayers.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# 过渡层\n",
    "class TransitionLayer(layers.Layer):\n",
    "    # out_channels代表输出通道数\n",
    "    def __init__(self, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv = layers.Conv2D(filters=out_channels,\n",
    "                                           kernel_size=(1, 1),\n",
    "                                           strides=1,\n",
    "                                           padding=\"same\")\n",
    "        self.pool = layers.MaxPool2D(pool_size=(2, 2),   # 2倍下采样\n",
    "                                              strides=2,\n",
    "                                              padding=\"same\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.bn(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# DenseNet整体网络结构\n",
    "class DenseNet(tf.keras.Model):\n",
    "    # num_init_features:代表初始的通道数，即输入稠密块时的通道数\n",
    "    # growth_rate:对应的是论文中的增长率k，指经过一个BottleNet输出的特征图的通道数\n",
    "    # block_layers:每个稠密块中的BottleNet的个数\n",
    "    # compression_rate:压缩因子，其值在(0,1]范围内\n",
    "    # drop_rate：失活率\n",
    "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n",
    "        super(DenseNet, self).__init__()\n",
    "        # 第一层，7*7的卷积层，2倍下采样。\n",
    "        self.conv = layers.Conv2D(filters=num_init_features,\n",
    "                                           kernel_size=(7, 7),\n",
    "                                           strides=2,\n",
    "                                           padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        # 最大池化层，3*3卷积核，2倍下采样\n",
    "        self.pool = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n",
    "        self.relu = layers.ReLU()\n",
    "        # 稠密块 Dense Block(1)\n",
    "        self.num_channels = num_init_features\n",
    "        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        # 该稠密块总的输出的通道数\n",
    "        self.num_channels += growth_rate * block_layers[0]\n",
    "        # 对特征图的通道数进行压缩\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        # 过渡层1，过渡层进行下采样\n",
    "        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "\n",
    "        # 稠密块 Dense Block(2)\n",
    "        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[1]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        # 过渡层2，2倍下采样，输出：14*14\n",
    "        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "\n",
    "        # 稠密块 Dense Block(3)\n",
    "        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[2]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        # 过渡层3，2倍下采样\n",
    "        self.transition_3 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "\n",
    "        # 稠密块 Dense Block(4)\n",
    "        self.dense_block_4 = DenseBlock(num_layers=block_layers[3], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "\n",
    "        # 全局平均池化，输出size：1*1\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        # 全连接层，进行10分类\n",
    "        self.fc = layers.Dense(units=10, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.dense_block_1(x)\n",
    "        x = self.transition_1(x)\n",
    "        x = self.dense_block_2(x)\n",
    "        x = self.transition_2(x)\n",
    "        x = self.dense_block_3(x)\n",
    "        x = self.transition_3(x,)\n",
    "        x = self.dense_block_4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def densenet_121():\n",
    "    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 24, 16], compression_rate=0.5, drop_rate=0.5)\n",
    "\n",
    "densenet_121 = densenet_121()\n",
    "\n",
    "densenet_121.build(input_shape=(50000, 32, 32, 3))\n",
    "\n",
    "densenet_121.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_net_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          multiple                  9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_62 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_block_4 (DenseBlock)   multiple                  339264    \n",
      "_________________________________________________________________\n",
      "transition_layer_3 (Transiti multiple                  33920     \n",
      "_________________________________________________________________\n",
      "dense_block_5 (DenseBlock)   multiple                  931968    \n",
      "_________________________________________________________________\n",
      "transition_layer_4 (Transiti multiple                  133376    \n",
      "_________________________________________________________________\n",
      "dense_block_6 (DenseBlock)   multiple                  4377600   \n",
      "_________________________________________________________________\n",
      "transition_layer_5 (Transiti multiple                  824960    \n",
      "_________________________________________________________________\n",
      "dense_block_7 (DenseBlock)   multiple                  5999616   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  16650     \n",
      "=================================================================\n",
      "Total params: 12,667,082\n",
      "Trainable params: 12,512,010\n",
      "Non-trainable params: 155,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the code of your DenseNet-169 model here.\n",
    "def densenet_169():\n",
    "    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 32, 32], compression_rate=0.5, drop_rate=0.5)\n",
    "\n",
    "densenet_169 = densenet_169()\n",
    "\n",
    "densenet_169.build(input_shape=(50000, 32, 32, 3))\n",
    "\n",
    "densenet_169.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train and evaluate your models. (25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train your models. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "45000/45000 [==============================] - 123s 3ms/sample - loss: 1.8888 - accuracy: 0.2913 - val_loss: 2.1789 - val_accuracy: 0.1478\n",
      "Epoch 2/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.7221 - accuracy: 0.3516 - val_loss: 2.6672 - val_accuracy: 0.1146\n",
      "Epoch 3/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.6205 - accuracy: 0.3897 - val_loss: 4.0611 - val_accuracy: 0.1378\n",
      "Epoch 4/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.5521 - accuracy: 0.4199 - val_loss: 2.0767 - val_accuracy: 0.2420\n",
      "Epoch 5/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.4833 - accuracy: 0.4486 - val_loss: 4.4022 - val_accuracy: 0.1640\n",
      "Epoch 6/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.4291 - accuracy: 0.4701 - val_loss: 2.2984 - val_accuracy: 0.2438\n",
      "Epoch 7/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.3685 - accuracy: 0.4944 - val_loss: 2.5415 - val_accuracy: 0.1884\n",
      "Epoch 8/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.3247 - accuracy: 0.5133 - val_loss: 2.3922 - val_accuracy: 0.2838\n",
      "Epoch 9/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.2816 - accuracy: 0.5310 - val_loss: 2.9392 - val_accuracy: 0.2084\n",
      "Epoch 10/30\n",
      "45000/45000 [==============================] - 100s 2ms/sample - loss: 1.2529 - accuracy: 0.5415 - val_loss: 2.2264 - val_accuracy: 0.3458\n",
      "Epoch 11/30\n",
      "45000/45000 [==============================] - 100s 2ms/sample - loss: 1.2201 - accuracy: 0.5546 - val_loss: 1.5106 - val_accuracy: 0.4460\n",
      "Epoch 12/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.1894 - accuracy: 0.5654 - val_loss: 1.9889 - val_accuracy: 0.3410\n",
      "Epoch 13/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.1587 - accuracy: 0.5784 - val_loss: 2.8228 - val_accuracy: 0.2894\n",
      "Epoch 14/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.1250 - accuracy: 0.5919 - val_loss: 1.7574 - val_accuracy: 0.4232\n",
      "Epoch 15/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.1108 - accuracy: 0.5986 - val_loss: 1.7641 - val_accuracy: 0.4082\n",
      "Epoch 16/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.0896 - accuracy: 0.6048 - val_loss: 3.3008 - val_accuracy: 0.1870\n",
      "Epoch 17/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 1.0618 - accuracy: 0.6150 - val_loss: 2.1013 - val_accuracy: 0.3370\n",
      "Epoch 18/30\n",
      "45000/45000 [==============================] - 98s 2ms/sample - loss: 1.0410 - accuracy: 0.6230 - val_loss: 1.8401 - val_accuracy: 0.4110\n",
      "Epoch 19/30\n",
      "45000/45000 [==============================] - 98s 2ms/sample - loss: 1.0185 - accuracy: 0.6340 - val_loss: 2.0486 - val_accuracy: 0.3710\n",
      "Epoch 20/30\n",
      "45000/45000 [==============================] - 98s 2ms/sample - loss: 1.0022 - accuracy: 0.6391 - val_loss: 1.9958 - val_accuracy: 0.4094\n",
      "Epoch 21/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9868 - accuracy: 0.6443 - val_loss: 3.8005 - val_accuracy: 0.2844\n",
      "Epoch 22/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9750 - accuracy: 0.6495 - val_loss: 1.3748 - val_accuracy: 0.5228\n",
      "Epoch 23/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9507 - accuracy: 0.6580 - val_loss: 1.2811 - val_accuracy: 0.5590\n",
      "Epoch 24/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9366 - accuracy: 0.6632 - val_loss: 1.5511 - val_accuracy: 0.5392\n",
      "Epoch 25/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9264 - accuracy: 0.6678 - val_loss: 1.8892 - val_accuracy: 0.4636\n",
      "Epoch 26/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.9045 - accuracy: 0.6754 - val_loss: 1.3115 - val_accuracy: 0.5686\n",
      "Epoch 27/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.8941 - accuracy: 0.6802 - val_loss: 1.2941 - val_accuracy: 0.5754\n",
      "Epoch 28/30\n",
      "45000/45000 [==============================] - 100s 2ms/sample - loss: 0.8788 - accuracy: 0.6868 - val_loss: 2.1104 - val_accuracy: 0.5070\n",
      "Epoch 29/30\n",
      "45000/45000 [==============================] - 100s 2ms/sample - loss: 0.8686 - accuracy: 0.6881 - val_loss: 2.1278 - val_accuracy: 0.4754\n",
      "Epoch 30/30\n",
      "45000/45000 [==============================] - 99s 2ms/sample - loss: 0.8566 - accuracy: 0.6923 - val_loss: 1.9325 - val_accuracy: 0.4904\n"
     ]
    }
   ],
   "source": [
    "# implement your code here.\n",
    "#Train densenet_121\n",
    "# 防止Tensorflow运行GPU内存不足造成错误\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"  #选择哪一块gpu\n",
    "config = ConfigProto()\n",
    "config.allow_soft_placement=True #如果你指定的设备不存在，允许TF自动分配设备\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.8  #分配百分之七十的显存给程序使用，避免内存溢出，可以自己调整\n",
    "config.gpu_options.allow_growth = True   #按需分配显存，这个比较重要\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "densenet_121.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = densenet_121.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=30,\n",
    "                    validation_split=0.1)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABDJ0lEQVR4nO3dd3iUVdr48e9JIwkJpBJCQkiA0DuhKAhWBBsWZLFjQ911Lbvrqu9vd11313ebr6uuuqy6NlZR7Kg0C4oUKSEhNFOAQAqkkUAapMz5/XESCCFlJpnJlNyf6+KaZOaZZ86TIXfOnHOf+yitNUIIITyDl7MbIIQQwn4kqAshhAeRoC6EEB5EgroQQngQCepCCOFBfJz1whERETo+Pt5ZLy+EEG4pOTm5WGsd2drjTgvq8fHxbNu2zVkvL4QQbkkpdbCtx2X4RQghPIgEdSGE8CBWBXWl1GylVLpSKksp9VgLjz+ilEpt+LdLKVWvlAqzf3OFEEK0pd0xdaWUN/AicAmQC2xVSi3XWu9pPEZr/Xfg7w3HXwk8rLU+amtjamtryc3N5cSJE7Y+VbTC39+f2NhYfH19nd0UIUQXsGaidDKQpbXeD6CUeheYC+xp5fgbgKUdaUxubi7BwcHEx8ejlOrIKUQTWmtKSkrIzc0lISHB2c0RQnQBa4ZfYoCcJt/nNtx3FqVUIDAb+LAjjTlx4gTh4eES0O1EKUV4eLh88hGiG7EmqLcUYVsr7XglsKG1oRel1CKl1Dal1LaioqKWX0wCul3Jz1OI7sWa4ZdcoH+T72OB/FaOXUAbQy9a65eBlwGSkpKk5q8Qols4Vl3LoZIqsksqOXS0ijGxvTkvsdX1Q51iTVDfCiQqpRKAPEzgvrH5QUqp3sBM4Ga7trALlZWV8c477/DTn/7UpudddtllvPPOO4SEhLR6zO9+9ztmzJjBxRdf3MlWCiFcidaa2npNWXVNQ+Cu4lBJJdklVRw8ar4urao94zn3nT/IeUFda12nlLofWA14A69prXcrpe5teHxxw6HXAGu01pUOaWkXKCsr46WXXjorqNfX1+Pt7d3q81asWNHuuf/whz90un1CCMfTWnOguJLUnDLSco9RXHGSE7X1VNXUU11bT3XDbVVNPSdq6qmqrafecubAg5eCmNAABoT15LLR0QwIDyQurCfxEYHEhQUS6Oe4xfxWnVlrvQJY0ey+xc2+fwN4w14Nc4bHHnuMffv2MW7cOHx9fQkKCiI6OprU1FT27NnD1VdfTU5ODidOnODBBx9k0aJFwOmSBxUVFcyZM4fp06ezceNGYmJi+PTTTwkICGDhwoVcccUVzJs3j/j4eG677TY+++wzamtref/99xk2bBhFRUXceOONlJSUMGnSJFatWkVycjIRERFO/skI4blKK2tIzS0j9VAZqTnm37Fq07Pu6edNVC9//H29CfTzJqiHD5FBPQjwM98H+PoQ4OdFoJ8Pwf4+xIUFMiC8JzEhAfj5OGdtp9Nqv7Tnyc92syf/uF3POaJfL564cmSrj//lL39h165dpKam8u2333L55Zeza9euU+mAr732GmFhYVRXVzNp0iSuu+46wsPDzzhHZmYmS5cu5ZVXXmH+/Pl8+OGH3Hzz2SNSERERbN++nZdeeomnn36aV199lSeffJILL7yQxx9/nFWrVvHyyy/b9fqF6M601pRU1rCvsIIfj5SfCuAHis3gglIwNCqYOaP6Mq5/COPjQhncJwhvL/dKNnDZoO4KJk+efEZ+9/PPP8/HH38MQE5ODpmZmWcF9YSEBMaNGwfAxIkTyc7ObvHc11577aljPvroIwDWr19/6vyzZ88mNDTUnpcjRLdQb9Hkllaxr6iCrMIK9hVWklVUwb6iCsqajG1HBvdgfP8Qrk+KZVz/EMbEhhDUw/1DosteQVs96q7Ss2fPU19/++23fPXVV2zatInAwEDOP//8FvO/e/Toceprb29vqqurWzx343He3t7U1dUBpichhLCe1pp9RZVsPlDClgNHST9Szv7iSmrqLKeOiQjyY2BkEJeNjmZQZBCD+wSR2CeI6N7+Hpny67JB3RmCg4MpLy9v8bFjx44RGhpKYGAgP/74Iz/88IPdX3/69OksW7aMRx99lDVr1lBaWmr31xDCnWmtySysYPP+En44cJTN+49SXHESMD3vMTG9mTEkkkGRPRncJ4hBkUGEBPo5udVdS4J6E+Hh4UybNo1Ro0YREBBAVFTUqcdmz57N4sWLGTNmDEOHDmXq1Kl2f/0nnniCG264gffee4+ZM2cSHR1NcHCw3V9HCHdRV285FcQ3HzjKlgNHKamsASC6tz/TB4czZWA4UweGEx8e6JE9b1spZ33kT0pK0s03ydi7dy/Dhw93SntcwcmTJ/H29sbHx4dNmzZx3333kZqa2unzdvefq3BtWmuKKk5yoKiS/cWVHCiuZH9RBfuLKzlUUkVdQ7pgTEgAUwaGMTXBBPH+YQHdMogrpZK11kmtPS49dRdy6NAh5s+fj8Viwc/Pj1deecXZTRLCburqLWSXVJFZUE5moZm4PFBcyYGiSspP1p06zs/Hi4TwngyNCmb2yL4M7hPEpPgw+ocFOrH17kOCugtJTEwkJSXF2c0QolPqLZqDJZVkFFSQWVBORqG53V9USU396QnMmJAABkb25NoJMQyMDCIhoicJESbH28vN0ghdiQR1IUSnVNXU8cP+EtZlFLPlwFGyiirOyD6JDQ1gSFQwM4dGMqRPMEOighnUp6dDV1V2Z/JTFULYRGtNekE536UXsS6ziK0HSqmpt+Dv68Wk+DCmJ8aT2CeIIVHBDO4TRE8PyP12J/LTFkK0q7SyhvVZxXyXUcT3mUUUHDdphEOjglk4LZ4ZiZEkxYfi79t6jSTRNSSoCyFOsVg0uaXVZBSUk1FYTlaBWVK/98hxtIbeAb5MT4xg5pBIZiRG0re3v7ObLJqRoN4JQUFBVFRUkJ+fzwMPPMAHH3xw1jHnn38+Tz/9NElJrWYg8eyzz7Jo0SICA83svjWlfIXoDItFk1fWELwLKsgsLCezwCyrr66tP3Vc317+JEYF8cCFicwcGsnY2BC3q4XS3UhQt4N+/fq1GNCt9eyzz3LzzTefCurWlPIVwhpaawqOnyS9oJzMgnLSj5ST0ZBSWFVzOnhH9erBkKhgbpgcx5CoIBIbxsN7B8iG5e5GgnoTjz76KAMGDDhVT/33v/89SinWrVtHaWkptbW1/OlPf2Lu3LlnPC87O5srrriCXbt2UV1dze23386ePXsYPnz4GbVf7rvvPrZu3Up1dTXz5s3jySef5Pnnnyc/P58LLriAiIgI1q5de6qUb0REBM888wyvvfYaAHfddRcPPfQQ2dnZrZb4Fd2T1priippTPe70gnIyGgL48ROnc8AjgnowJCqI+Un9GRIVbAJ4n2B6B0rw9hSuG9RXPgZHdtr3nH1Hw5y/tPrwggULeOihh04F9WXLlrFq1SoefvhhevXqRXFxMVOnTuWqq65qdSXbv/71LwIDA0lLSyMtLY0JEyaceuypp54iLCyM+vp6LrroItLS0njggQd45plnWLt27Vl105OTk3n99dfZvHkzWmumTJnCzJkzCQ0NtbrEr/AsjasvMxtywDMLK8zXheVn7K7TO8CXoVHBXDm2H0P7BpPYxwTw8KAebZxdeALXDepOMH78eAoLC8nPz6eoqIjQ0FCio6N5+OGHWbduHV5eXuTl5VFQUEDfvn1bPMe6det44IEHABgzZgxjxow59diyZct4+eWXqaur4/Dhw+zZs+eMx5tbv34911xzzalqkddeey3ff/89V111ldUlfoV7q6mz8F1GEWvTC81CnoKKUxs4APTy92FIVDCzR/UlsU8wiVEmlbBPcI9uuYReuHJQb6NH7Ujz5s3jgw8+4MiRIyxYsIC3336boqIikpOT8fX1JT4+vsWSu0219Mt04MABnn76abZu3UpoaCgLFy5s9zxt1eWxtsSvcD8Wiyb5UCmfpOTxxc7DlFXVEuzvw/C+vbh8TPSpHPDEPkFESvAWzbhuUHeSBQsWcPfdd1NcXMx3333HsmXL6NOnD76+vqxdu5aDBw+2+fwZM2bw9ttvc8EFF7Br1y7S0tIAOH78OD179qR3794UFBSwcuVKzj//fOB0yd/mwy8zZsxg4cKFPPbYY2it+fjjj1myZIlDrls4X1ZhOZ+k5PNJah65pdUE+Hoza2QUV4+PYfrgCHy9nbM9mnAvEtSbGTlyJOXl5cTExBAdHc1NN93ElVdeSVJSEuPGjWPYsGFtPv++++7j9ttvZ8yYMYwbN47JkycDMHbsWMaPH8/IkSMZOHAg06ZNO/WcRYsWMWfOHKKjo1m7du2p+ydMmMDChQtPneOuu+5i/PjxMtTiQQqPn2D5DhPId+Udx0vB9MRIfjlrCLNG9JXVmMJmUnq3G5Cfq+uot2h25h1jQ1Yx32cWseXAUSwaxsT25upxMVwxNpo+wbKgR7ROSu8K4URmu7UK1mcWs2FfCT/sL6G8IcVweHQvfnbBYK4eH8OgyCAnt1R4CgnqQtjZ4WPVbMgqYUNWMRuyiiksN3VS+ocFcMWYaM4dFME5g8KJkPRC4QAuF9S11jKbb0eymXXXOFBcyYqdh1mx8zC7848DEN7Tj3MGhTN9cATTBkfIJg+iS7hUUPf396ekpITw8HAJ7HagtaakpAR/fxmjdYR9RRWs3HmYL3YeYe9hE8jHx4Xw+JxhzBgSydCoYNnsQXQ5lwrqsbGx5ObmUlRU5OymeAx/f39iY2Od3QyPkVVYzhdpR1i56zA/HikHYOKAUH57xQjmjOpLvxAp1SCcy6qgrpSaDTwHeAOvaq3PWhmklDofeBbwBYq11jNtbYyvry8JCQm2Pk0Ih9Bac/jYCdJyj7Ejt4yv9xaQUVCBUjBpQBhPXDmCOaOipfyscCntBnWllDfwInAJkAtsVUot11rvaXJMCPASMFtrfUgp1cdB7RXCYQqOmwC+M7eMtLxj7Mo7RnFFDQDeXoqJA0J58qqRzB7Vl6heEsiFa7Kmpz4ZyNJa7wdQSr0LzAX2NDnmRuAjrfUhAK11ob0bKoQ9lVXVkJpTRmpOGTtzj5GWd4yihiwVLwVDooI5f2gfxsT2ZnRMb4ZH95JdfYRbsCaoxwA5Tb7PBaY0O2YI4KuU+hYIBp7TWr/V/ERKqUXAIoC4uLiOtFcIm9XVW0gvKCflUJn5l1PK/qJKAJSCwZFBnJcYweiY3oyJ7c2I6N4E+EkAF+7JmqDe0vR98zw5H2AicBEQAGxSSv2gtc4440lavwy8DGZFqe3NFaJ9pZU1bM0+SkpOGSmHSknLPXZqQ4jwnn6MjwvlugmxjI8LYUxsCEGyFF94EGv+N+cC/Zt8Hwvkt3BMsda6EqhUSq0DxgIZCNFFducf4/UN2SxPzaem3oKPl2Jkv17MT+rP+LgQxvcPpX9YgKTLCo9mTVDfCiQqpRKAPGABZgy9qU+BF5RSPoAfZnjmH/ZsqBAtqbdovvmxkP+s388P+48S4OvNgsn9uWpsP0bF9JZxcNHttBvUtdZ1Sqn7gdWYlMbXtNa7lVL3Njy+WGu9Vym1CkgDLJi0x12ObLjo3ipO1vH+thze2JjNwZIq+vX25/E5w1gwKU62ZhPdmktVaRSiPTlHq3hzYzbvbc2h/GQdE+JCuHP6QC4dGYWP1BsX3YBUaRRuT2vNlgNHeWNjNqt3H8FLKS4bHc3t0+IZHxfq7OYJ4VIkqAuXVV1Tz6epeby56SB7Dx+nd4Av98wcxK3nDCC6tyzHFzbSGo7lQM4WqK+BsTeYnFYPI0FduJyco1X894eDvLcth7KqWob1DeYv145m7rgYyR8X1quthvxUyN1iAnnuNqg4cvrxsIEQN9VpzXMUCerCJWit2bivhDc2ZvP13gKUUswaEcVt58YzJSFM0hBF+yqK4MB3DQF8CxzZCRazIQmhCZAwA/pPhuix8M582PSCBHUh7K3yZB0fpeTx1sZsMgsrCOvpx70zB3Hz1AFS8VBYr74W/j0DyvPBNxBiJsK5P4fYyRA7CYIizzw+6Q74/hk4ut/02D2IBHXR5WrrLazPLGb5jnxW7z5CVU09o2J68fd5Y7hybD/JLRe2O7TJBPQrn4NxN4N3O6Ft8iLY8Dz88C+47O9d08YuIkFddAmLRZN8qJRPU/P4Iu0wpVW19PL34aqx/bg+KZYJcaEyxCI6LnMNePvBqHntB3SA4L4w+npI+S+c/zgEhjm+jV1EgrpwGK01ew+Xs3xHPp/tyCevrBp/Xy8uHh7F3HExzBgSQQ8f6ZV7jJ0fwA8vwYW/gUEXdu1rZ6yBAdOghw0beJ/zM9jxDiS/Duf90nFt62IS1IXdHTl2gg+Sc/g0NZ/Mwgq8vRQzEiN45NKhXDwiSgpoeaKDG+Hje83XS66BcTfBrD91TQ+4NBuK0yHpdtue13cUDLwANr8M5/wcfPwc0ryuJr9dwi601iQfLOX1jdms3nWEOotmUnwof7x6FJeN6kt4UA9nN1E4Ssk+ePcmCI2HhZ/D5n/Dhucg80szXj1irmPzwTPWmNvEWbY/99z74b/Xwa4PYdwN9m2Xk0hQF51yorae5TvyeXNjNrvzjxPs78PCc+O55ZwBDAjv6ezmCUerLoV3fgJouPE9M1Z98RMw8hpYfj+8fxsMuwIuexp6RTumDZmrIWwQhA+y/bmDLoLI4Sa9cewCj1iMJEFddEh+WTX//eEgS7ccorSqliFRQTx1zSiuGR9DoJ/8t+oW6mth2a1m+OPWT88MqtFj4K5vTLD89s/w4hSY9UeYcKt9A2dNFRz4Hibd2bHnK2XG1pffD/u/hUEX2K9tTiK/fcJqWms2HzjKmxuzWbOnAK01lzQsEDpnYLhkr3QnWsMXv4QD6+Dqf0H8tLOP8faB6Q/B8Cvhswfhswdg5/sm7bAjveqWHFgH9Sc7NvTSaMx8+PoP5g+QBHXRHRworuTzHfks32EmPkMCfbnrvARumTqA2NBAZzdPOMOmF2D7mzD9FzCu+fYKzYQPgluXQ8pbsOa38K9z4YL/B1N/al36YVsyV4NfkMl86SifHiZvfe2foHAv9BneuTY5mQR10aLc0io+TzvM52n57Mo7DsDk+DD+ep2pwSILhLqxH78wwXnEXLjwt9Y9x8sLJi40PeovfgVf/haqiuGSP3S8HVqbSdKB53c+cyXpDvj+/2DTizD3hc6dy8kkqItTCo6f4Iu0w3yWlk/KoTIAxvYP4TeXD+fyMdFSGVHA4R3w4V3QbzxcvdgEa1v06gcL3ob3F0LyG2bhj28H/18V7oXjuTDz1x17flM9w032S8p/4aLfQVCfzp/TSSSod3NVNXV8tD2Pz3bksyX7KFrDiOhe/Hr2UK4Y3Y+4cBleEQ2O58M7CyAgDG5YCn4d/L+hFEy+G/Z8Ars/bn/4pjWZq81tZ8bTm5r6M9j2Omx5BS78f/Y5pxNIUO+mtNYs35HPn1f8yJHjJxjcJ4iHLhrCFWOjGRRpw6o80T3UVMLSBXDyONyxyqQudsaAaRAxBLa91vGgnrEG+o6xX6pkxGAYOge2vgrTH+74Hy0nk6DeDaXllvHkZ3tIPljK6Jje/PPG8SQNkNorohUWC3x8jyllu2Ap9B3d+XMqBRNvh9WPw+E0kwJpi+pSyNkM5/2i821p6pz7IX0F7Fja8TRJJ5NNHbuRwvITPPL+Dq56YQMHS6r427wxfPqzaUyKl3rlog1r/wR7P4NZT8HQ2fY779gF4ONvaq/YKutr0PX2G3ppNOBcM1/ww0vmj5kbkqDeDZysq2fxd/u44O/f8klqHvfMHMjaX81kflJ/vLwkmIs2WCwmI2TkNTD1PvueOzAMRl4LacvgZLltz838EgLDTd10e1LK9NZLsk6P2bsZCeoeTGvNmt1HmPWPdfxl5Y+cMyiCNQ/P5PE5wwn293V284Q7qCiAuhNmDNwRn+aS7oCaCrMoyVqWesj6EgZfDF4OSK0dMRd6xcJG90xtlKDuoTIKyrnlP1tYtCQZP28v3rpjMq/elkRChNRjETYoO2huQ+Mdc/7YJIgaDVtfM3nn1sjbDlUl9h96aeTtC1PvhYPrIT/FMa/hQBLUPUxVTR1/XrmXy577nrTcMn5/5QhWPHgeM4ZEtv9kIZorbQjqIQMcc36lTMncgp2Ql2zdczJXg/KCwRc5pk1gatT4Bbtlb12CugdZs/sIlzyzjn9/t59rJ8Tw7SMXsHBaAr7e8jaLDmrsqYfEOe41xsw3S/23WTlhmrkG+k+BgFDHtcm/twnsuz+GY7mOex0HsOq3XSk1WymVrpTKUko91sLj5yuljimlUhv+/c7+TRWtyS2t4q43t7FoSTJBPXx4/95z+Nu8sYT19Iyi/8KJSg9CUF/w9Xfca/QIhtHzTE3z6tK2jy0/Yla1OmropampDZt+rPg11Nc5/vXspN2grpTyBl4E5gAjgBuUUiNaOPR7rfW4hn+dKOggrFVbb2Hxd/u45Jl1bMgq5vE5w/j8gelMivec/RaFk5UdhFAHDb00lXQH1FXDjvfaPi6zYUOMIZc6vk0hcXDpU5D+hcnTt9Q7/jXtwJrFR5OBLK31fgCl1LvAXGCPIxsm2rblwFF+88lOMgoquGREFL+/aiQxIVKbRdhZ6UGIm+L414kea9ITt70GU+5pPdMmY7XJTOnTUr/SAabeB7XV8PWTpprjVS/YXu+mi1nTuhggp8n3uQ33NXeOUmqHUmqlUmpkSydSSi1SSm1TSm0rKirqQHPF0coaHnl/B/P/vYnKk/W8cmsSr9yaJAFd2F99rSmY5ahJ0uaS7jB7jR7c2PLjdSfNRhZDZnXtDkXn/cIUHkt9G7542PosHSexpqfe0k+v+VVtBwZorSuUUpcBnwCJZz1J65eBlwGSkpJc+yfjgtbsPsKvP0yj4kQd984cxAMXDZZdhoTjHMsFbema4RcwC5FW/Y/prbe06cahTSanvSvG05ub+ajJ11//D7MKdvZfXHbrO2t66rlA/ybfxwL5TQ/QWh/XWlc0fL0C8FVKRditld1cvUXzf2vSWbQkmf6hgax48DwemzNMArpwrDIHpzM25xdoyt/u+RQqWvgkn7EGvHtAwoyuaU9TSsFFT5hKjpsXw5e/61iPvb4OUpeayV4HsSaobwUSlVIJSik/YAGwvOkBSqm+qqF4iFJqcsN5S+zd2O7oWFUtd765lX9+k8X1E2N5/95zGBIV7Oxmie6gMUe9q3rqYIp8WWrNUEdzmash4Tzwc9ICOqXMxOmku2Dj87D2f61/bl0NJL8JL0yET+6F1Hcc1sx2u3pa6zql1P3AasAbeE1rvVspdW/D44uBecB9Sqk6oBpYoLWLDzy5gfQj5Sxaso38smr+ePUobp4SJ4W3RNcpOwjK20xMdpU+wyDuXFPk69wHTk9Kluwz9Vgm39N1bWmJUjDn72Z8f93fzI5LMx5p/fi6k5CyBNY/C8dyIHocLHgHhsxxWBOt+vzeMKSyotl9i5t8/QLgfkuvXNjnafk88n4aQf4+LL17KkmSpii6WulB6B3T+X1EbZV0B3x0F+xfe3rVaOaX5jbxkq5tS0u8vMzm2fW18M2fzJDQtAfOPKamyuzhuuE5KD8MsZPhin+YejUO7pjJoKyLqau38Pc16fz7u/1MiAvhXzdPJKqXAxd+CNGaskNdN57e1IirYFW46a2fCuqrzaYaYQld356WeHnD3Beh/qTZb9Wnh0nFPFlhJno3Pg+VRTBgOlyzGBJmdtnEqgR1F1JaWcPPl6awPquYm6bE8cSVI/Hzce2cWOHByg46p2fs0wPG3WRK/h4/bFacZq+HyYu6vi1t8faBa18xPfaVv4b8VMhYBdVHzWbYM37dchaPg0lQdxG78o5x73+TKTx+kr9eN5qfTHJgrQ0h2lNbbcruhsQ75/UnLjS93ZQlEDUS6mu6ZhWprbx9Yd5r8N7NsOMdk2454xHoP9lpTZKg7gI+2p7L4x/tJDTQj2X3nsO4/iHObpLo7soOmduuzHxpKnwQDLwAkt+AQReYiolx5zinLe3x6WG2+Tue67gSxTaQz/ZOdKyqlp8vTeEXy3Ywtn8In/18ugR04RocXXLXGkl3wPE8k9c96ALTK3ZV3j4uEdBBeupOszGrmF++v4Oi8pP88pIh3Hf+IHykRK5wFWVOyFFvbugcUyGy4ohrDr24KIkiXexEbT1//HwPN766mQBfbz766bn8/KJECejCtZRmm+XwQVHOa4O3r9lAw9sPBrtAKqObkJ56F9p7+DgPvZtKekE5N0+N438uGy5L/YVrKjtoSs86e7Hbeb8ym2gEO/GPi5uRiNIFLBbNq+v38/TqDHoF+PL6wklcMKyPs5slROtKDzp3PL2Rtw+EDXR2K9yKBHUHyyur5pfLUvlh/1FmjYjiz9eOJjyoh7ObJUTbyg46NS1PdJwEdQf6NDWP33yyC4tF87frxnB9UqzUbhGur7oMThxzjZ66sJkEdQfQWvPUF3t5df0BJsSF8I+fjGNAuJMqyzmD1qYWd0j/9o8VrqcrNpsWDiMpF3ZWb9E8+mEar64/wG3nDGDZPed0r4AOkPJfeG4sHN3v7JaIjnBGyV1hNxLU7ehkXT0/X7qdZdtyeeDCwfz+qpHdM1Vxzyeg681+ksL9dPXmGMKuumHEcYyqmjrufiuZFTuP8JvLh/OLWUO75/j5yXI4sM58LUHdPZUehB69ICDU2S0RHSBj6nZwrLqWO9/YyvZDpVKMK+trU3wpJgkObjClSHsEObtVwhaNJXe7Y6fEA0hPvZOKK05yw8s/sCO3jH/eMKF7B3SA9JWmh3fhb0xw3/+ts1skbFV2UMbT3ZgE9U7IK6tm/uJN7C+u4JVbk7h8TLSzm+Rc9XVmM4PESyF+uvkInylDMG5Fa+dtjiHsQoZfOmhfUQW3vLqZ8hN1LLlzCpNkuznI+QGqS00hJm9fU1kv80sTKOSjvHuoLILaKumpuzHpqXfA7vxjzF+8iZN1FpYumioBvVH6yobiSw1bkCVeavZnPLKza9uRmwyH07r2NT2FK5TcFZ0iQd1G27KPsuDlH+jh48Wye89hVExvZzfJNWgNP34BCTPM9mNweiu0rhyCsdTDkmvg3+fB2/Mhd1vXvbYncIWSu6JTJKjbYNO+Em75zxYignrw/n3nMihSsjpOKUqH0gNm6KVRUB/oNx4y1nRdOwr3wMljMGQO5G6BVy+Ct66Ggxu7rg3urDTb3MpqUrclQd1K6zOLuf2NLcSGBvDePVOJCQlwdpNcS/oKcztkzpn3J14KuVuhsqRr2nHoB3M756/w0C645A9QsAtenwOvX26ycbTumra4o7KD0DMS/LrZKmgPIkHdCt9lFHHnm1sZENaTpYum0ifY39lNcj3pKyB6HPSOOfP+IbMADfu+7pp25Gw2u+WExJn8+GkPwoNpMPsvcHQfvDUX/jPr9ASuM1UUQl2Nc9vQnKuU3BUdJkG9HWt/LOTut7YxMDKIpYumEiFlc89WXmDGroddfvZj0eOhZ5+uW12asxnippyZbeMXCFPvgwdS4fL/g+P58PY8eOUCyPyqa9rVXE0lvDQV3roK6mvtc06LBb7+Y+fWBkiOutuzKqgrpWYrpdKVUllKqcfaOG6SUqpeKTXPfk10nq/2FHDPkmSGRAWx9O4phPX0c3aTXFPGKkCfOZ7eyMvLTJhmfWXy2B3p+GGTY91/asuP+/rDpLvggRS48nmoOgrvzIfyI45tV0t2fgBVJXBoE3z1e/ucc93f4funYeMLHXu+pb6huqYEdXfWblBXSnkDLwJzgBHADUqpEa0c91fAI1abrNp1hPveTmZ4dDBv3zmVkEAJ6K1KXwm94yBqVMuPJ14CJ8rM2Loj5TSMp/ef0vZxPn4w8Ta46nlTeKw407Htak5r2PoK9BkJk+6GTS/AnuWdO2f6Svj2f8E30MwrdOQP6PE8sNRJT93NWdNTnwxkaa33a61rgHeBuS0c93PgQ6DQju1zihU7D3P/O9sZFdObJXdNoXegr7Ob5LpqqmD/WtNLb22B0aALwcsHMh2cBXNoM/gEQPQY644PTTC3XV0iOHebyd2fdCdc+hTETIRPfwYl+zp2vuJM+GiRmdO47GmoKYcjHcjTlxx1j2BNUI8Bcpp8n9tw3ylKqRjgGmBxWydSSi1SSm1TSm0rKiqyta1d4rMd+fx8aQrj+ofw1h2T6eUvAb1N+9dC3YmWh14a+feGuHMcH9RzNpsA6W3le9Y7Frx8TSpmV9r6KvgFmw2VfXrA9W+Alzcsuw1qq20714nj8O6N5pp/8t/TC78ObrC9XZKj7hGsCeotdb+apw08Czyqta5v60Ra65e11kla66TIyEgrm9h1PknJ48F3U5g4IJQ375hMsAT09qWvMDVeBkxr+7jEWSa18FiuY9pRU2V6p7bsq+nlbQJYV/bUK0tg90cwdsHpRVohcXDtq+bns+JX1p/LYoGP7zU9/OvfNDtNBfeFsEGQ3YGgXnoQUNAr1vbnCpdhTVDPBZruSxYL5Dc7Jgl4VymVDcwDXlJKXW2PBnaVD5JzeXhZKlMSwnnj9kn07CFlcdplqYf0VWbM3KedOYchl5pbR/XW85LNeHBcK5OkrQkbCEe7sKee8papXjnpzjPvT7wYZjxido3avsS6c33/NKR/YYZwEs47ff+Ac+HQRhP0bVF2CHrFtP9eCpdmTVDfCiQqpRKUUn7AAuCMWR2tdYLWOl5rHQ98APxUa/2JvRvrKCt2HuaRD3YwbVAEry2cRKCfBHSr5G6DqmIYeln7x0YMMT1SR60uzdlsbmMn2fa80AQT1LsiZ91SD9tegwHToc/wsx8//zFImGl66+3Vy0lfBWv/F8YsgCn3nvlY/HSzcXThbtvaJ+mMHqHdoK61rgPux2S17AWWaa13K6XuVUrd2/azXd/ew8f55bIdjO8fwqu3JRHg5+3sJrmP9BVmAnTwxe0fq5RZXXrgO6g9Yf+25GyGiKEQaGNxtbCBZmKxqgtWvGZ9ZXrDk+9q+XEvb7juPxAQBstuNYG5JcVZ8NHdZkL4ymfPnqBuHAqzdQhGFh55BKvy1LXWK7TWQ7TWg7TWTzXct1hrfdbEqNZ6odb6A3s31BHKqmpYtGQbvQJ8WHzzRPx9JaDbJH2FCSABIdYdP+RSU9b14Hr7tsNiOb3oyFZhXZgBs/VVCIqCYVe0fkxQJFz/ugn+n/z07E8QzSdGfVsoVxHS33wqsuXnXHfSVNSUnrrb67YrSuvqLfx8aQoFx06y+OaJ9OklS/9tUpwFxRnWDb00ip9uUg7tPQRTnGF6ta0tOmpL2EBz6+hx9aMHTGmCiQvbz86Jm2pq1vz4OWx68fT9Fgt8ch+UZJmMmbaKbg2YboqYWTusVJYDaOmpe4BuG9T/tjqd7zOL+dPVoxgfJxvs2ixjpbltK5WxOd8AGDjTlOK15xi2tYuOWhISByjH99STXwflBRNus+74qT+F4VfCl7+Dg5vMfd//nwn0s/5kShy3JX6aGVIq+tG61yvLNrfSU3d73TKof5qax8vr9nPrOQOYP6l/+08QZ/txhVlBamsQSLzElHctybJfWw5thsAICB9k+3N9ekDv/o7NVa89YTJahl12dsGz1igFc180P9/3F5qsmLVPwej5po5Newaca26tzVeXhUceo9sF9V15x3j0wzQmJ4Tx2yvOqnYgrFFZYnrHtvTSGyU2pDbas8BXzmbTS+/olnlh8Y7tqe/5BKqPmroztvDvDfOXmBILn/4M+o6GK5+z7jpDEyC4n/WTpWUHza5Vwd18n10P0K2CeknFSe5ZkkxooB8v3TQBX+9udfn2k7kGtMW28fRGIf2hzwj77YZUUWRK6tqy6Kg5R+eqb3kFwhNNuqKt+o4yPfbosWZi1C/QuucpZYZgDm6wbqir9KD5xOIlvxPurtu8g7X1Fu5/J4WiipP8+5aJUkK3M9K/MD266HEde37iLDOJd+J459vSmJ9u66KjpkITTL69PdrTXH4K5G0zi406+kli9Dy4Z53tQ10DpkFFgXU1ZSRH3WN0m6D+vyv2sml/CX++ZjRjYkOc3Rz3VXsCsr4xQy8d7dUlzjKrP/ev7Xx7cjabYYOO/oGB0xkwjhhX3/ofUzlx7A32P3d74qebW2tSGyVH3WN0i6D+YXIur2/I5o5pCVw3UepadMqBdVBb2bGhl0b9p5jxYnuUDMjZbAK6bydSUh2Vq15dauqmj77e+lx+ewofbDYoaW9/1pPlZsxfeuoeweODelpuGY9/vJNzB4XzP5cNc3Zz3F/6CvDtCfHntX9sa7x9YNBFJm/b1vokTdWeMMMbHVl01NSpErx27qmnLoW6atsnSO1FKZMFk93OuLpkvngUjw7qReVmYjQyqAcv3DgBH5kY7RyLxexyNPiizvWMwawurSiAIzs6fo7DO0xxrI4sOmqqR5Dp0dqzp26xmBWksZOtr+/uCPHT4Xju6bK6LZGSux7FY6Oc1pqH30ultKqGf98yUbais4fDKWYpeWeGXhoNvhhQnVtdemrRUScyXxqFDTT58/Zy4DuTleOsXnoja+rAnOqpxzu8OcLxPDaob8gqYX1WMY/OHsaomN7Obo5nSF9pVkUmzur8uXpGmA0tOpPaeGizCcZBfTrfnrAE+/bUt74KgeEwoqVNwrpQ5DBTIKytRUhlh8AvyPZiaMIleWRQ11rzzJfp9Ovtz41T2qiPIWyTvsrsYNQz3D7nG3Ip5G03uea20rph0VEnh14ahQ00e3TauvNQS47lmbmH8bd0fpiqs7y8zLh6m0G9IfOloymXwqV4ZFD/NqOI7YfKuP/CRHr4SOVFu6guMzvzdGQBTWsSZwHalKS11dH9JrfcHkMvcHqytLSNsWdrJb9u/ugk3dH5c9nDgGlmaOlYXsuPlx5suziYcCseF9S11vzjywxiQwOYJ+mL9pO3DdD2C6JgVkn2ioHkN2wv8HWoYTy9M4uOmrJXrnpdDSS/aT6FuMrEY3zDuHpLvXWtZeGRh/G4oP713kLSco/xwIWJ+Pl43OU5T85WQJlxcHtRyuz2k/MDpC2zsT2bTa57xFD7tMVeueoZq6Cy0PkTpE1FjYIevSG7hUVIVUehpkLSGT2IR0U9i0XzzJcZDAgP5NoJVlbDE9bJ3WJqtvj3su95x91s/lB8+VvblunnbDbpgvaqVRIQav5IdDZX/eBGs4J04AX2aZc9eHnDgHNa7qlLyV2P41FBfc2eI+w5fJwHL0qUnHR7slggNxn627j/pzW8vOCyv0NFIXz3V+ueU3XU1Anv7KKjppRq2K+0kz31/BQzrOTtYvvcDphmyh2XF5x5vyw88jgeE/ksFs0/vsxkYGRP5o6TXrpdFafDyWOmZ+wIMRNhwq2weTEUWrGpQ+42c2uvzJdGYQM7N6ZeX2cWRPUbb7822Utr4+qy8MjjeExQ/2LnYdILynno4iF4e0lqll3lbDG39pwkbe6iJ0yu9MpH2p80zfkBlDfETLBvG8ISTM52fV3Hnl+cbsoCuGJQ7zvW/HybB/XSgyaPvUewc9ol7M4jgnq9RfPsVxkMiQri8tFS5N/ucreYMefwwY57jZ7hcOFvTMGwPZ+0feyhzWbpvV9P+7YhbKCpHnksp2PPz9tubvvZ+Y+NPXj7mEJqzVeWSuaLx/GIoL58Rx77iiqll+4oOVvN0IujF6ck3WF291n9/6CmsuVj6mshL9n+Qy/QpLBXB8fV81OgR6/T6ZGuJn4aFO01O1c1kpK7Hsftg3pdvYXnvspkeHQvZo/s6+zmeJ6qo2ZYwRGTpM15ecNlT5uVneuebvmYI2lmiMOek6SNOpur3jhJ6qq7Bw1orK/e0Fu3WMynEumpexQX/d9nvY9T8sguqeLhixPxkl66/eUlm1tHTZI2FzfVbCix8Z9Q3MLm1Icadjrq74CgHtwXfAI6ltZYV2NW3Np7nN+e+o0319dYX738sKlyKT11j+LWQb223sLz32QyOqY3l4yIcnZzPFPOFlPEy56Ljtpz8ZPg4w+rHj170jRnM/SOg1797P+6SjUU9upAUC/cbQKkK06SNvLxM5+4GndCkswXj2RVUFdKzVZKpSulspRSj7Xw+FylVJpSKlUptU0pNd3+TT3bB8m55Byt5heXDEFJMSLHyN0CfUaamuNdJTgKLnjc1IRJX3n6/sYiXo4YemnU0Vz1/BRz68pBHcwQzJFdZlcmKbnrkdoN6kopb+BFYA4wArhBKTWi2WFfA2O11uOAO4BX7dzOs5ysq+eFb7IY1z+E84dGOvrluidLveMWHbVn8iKIHG56642VE8sOmSEDRwy9NApLMMWvbN2RKW+7SQ109aGM+GmANrVzyg4BCkL6O7tVwo6s6alPBrK01vu11jXAu8AZRaK11hVan/qc3BOwsTqT7ZZtzSGvTHrpDlX0I9SUOzaItsbbFy77mwk8G54z9+U4cDy9UViCmYitOGLb8/JTTS/d1f8vxiSBdw9TB6bsIARHg08PZ7dK2JE1QT0GaJq4m9tw3xmUUtcopX4EvsD01s+ilFrUMDyzraioAzW0G5yoreeFtVlMig/lvMSIDp9HtKNx0VGsE3rqAAkzYOS1sP4fpvecs9ksoIka6bjXbMyAsWVcvbYaCve4/tALmPrusUlmsrRUctQ9kTVBvaWux1k9ca31x1rrYcDVwB9bOpHW+mWtdZLWOikysuNDJku3HKLg+Ekell66Y+VsMbv3ODPvetafzETt6v9nMl9ik0zqo6N0JFf9yE7Q9a6d+dLUgGmmnEHRXtcfLhI2syao5wJNB91igfzWDtZarwMGKaUc0oWurqnnxbX7mDowjHMHSS/doXK3dM2io7b0joEZj8CPn0PBTscsOjrj9fqDl49tueruMknaaMC55o9QVYn01D2QNUF9K5ColEpQSvkBC4DlTQ9QSg1WDV1mpdQEwA8oOetMdvBpah7FFSf5xSV2qqMtWlZ11FT1c8YkaXPn/AzCBpmvHZn5AmY5fUicbT31vO0Q1NcxaZaO0H+y+cMFsuORB2q3PqjWuk4pdT+wGvAGXtNa71ZK3dvw+GLgOuBWpVQtUA38pMnEqV3NT+pP/7BAJifIJrkOlbvV3HbVoqO2+PSAq/5pSvN2xaRt2EDbxtTzU9ynlw6mZk6/CeaTmAy/eByrij5rrVcAK5rdt7jJ138FrCyG3TleXoppg2XYpV3r/2EKcA2/smPPz9nimEqIHRU/DeKXt3+cPYQmmHo3Wrc/9HSyHIozYNR1XdM2e4mfZoK6DL94HBer5C/sorIEvv6jGQ4YelnHJhZzt0DfUfavhOgOwgaa+vHVpRDYzifCwzsA7Tp//Kw15V6zP2xvyVH3NG5dJkC0ImOlmQg7lmNWZdqqvs6ME7vC0Isz2LJfaeMkafQ4hzXHIYL7wuS7XT+vXthMgron2vuZ6YEFRcG212x/fuEesxmxIzfFcGW25KrnpzT8rGVVs3ANEtQ9zYnjsO8bGH6V2SIuY3XDcnAb5Dp50ZGzhQwAlHU99bzt7jVJKjyeBHVPk7nGVAscfiVMuM18vN7+lm3nyNkKPSMhNN4hTXR5vv5mvLm9XPXqUnOMBHXhQiSoe5q9n0HPPmboJKQ/JM4yQb2+1vpzuMKiI2cLs6JaY36quZWgLlyIBHVPUlsNmV/C8CtOZ7wk3QEVBfDjF9ado7LYBLPuOp7eyJq66vmNe5KOc3hzhLCWBHVPsu8bqK08Mzd98MVmUwlrJ0wbFx1196AemgCVhSYPvTX5KWZSNSC069olRDskqHuSvZ+BfwjEn3f6Pi9vmHgbHPiu5e3hmsvZYpaQd/chhVP7lWa3fkyem60kFd2CBHVPUVcD6SvMYiNv3zMfG3+LCdTJr7d/ntyt0Hc0+AY4pp3uor1c9YpCOJ5rltsL4UIkqHuK7O/hxLGWywIER8GwKyD1bag90fo56uvMRtPdddFRU6dK8LYyri6TpMJFSVD3FHs/A9+eMOiClh9PusOk4O35pPVzFOyC2ioZTwfw7wWBEa331PO3Awqix3Rps4RojwR1V9GZopaWelNvfMis1odNEmaYAl9tTZieqszYTRcdNRc2sPVc9fwUiBwKPYK7tk1CtEOCuq3ykju223xrtIb/zILPH+r4OXI2Q2VR2xUZlYKJt5tjj+xq5TxbTF1wqbFttJbWqLX7ldsV3YYEdVtY6uHt6+GjRfY7Z16yCbTJb5wep7XV3s/MZsKJs9o+btyN5rjWJkxzt5hNMbrzoqOmwgbCsVyoO3nm/cfzTe6/BHXhgiSo2yJ3m9kCLHcrFOyxzzlTloBvoNkLdM1vbB+G0doE9UEXtj8UEBgGo66FHe/ByYozH6soMul7Mkl6WmgCoM0GzU2d2r5OMl+E65GgbouMVWbjCG8/2+uptKSmEnZ+CCOuhvMfNxksGattO0d+iimxa+1mGEl3QE057PrgzPsbi3jJJOlpp3LVmw3B5KeYFNG+o7q+TUK0Q4K6LTLXQNxUkx6Y9m7b6YHW2LPcBNjxN8PEhWYi88vfmdRCa+39zPyhGTrHuuNjJ0HUKNj6nzM/FeRsBi9f96sL7kit5arnb4c+wyWXX7gkCerWOpZrUv6GXGpWaFaXmoDaGSlLTG9wwLlmwdDFT0JxOqRY+SlAa9i7HOKnt79DTyOlIOl2OJJmysY2ytlq0vN8/W2/Dk8VGA49ep05WSqTpMLFSVC3VuOwSOKlED/D1Nze/mbHz1eyDw5uML30xonJYZdD3Lmw9n/brjnSqOhHKMmCEVfZ9tqj55uc9sb0xvpaE6hkPP1MSpnyw0176qXZ5g+6BHXhoiSoWytzjUn1ixwKXl5mA4rs701w7ojUt0F5wdgbTt+nFMz6k0lP3PBc++fY+xmgzHCQLfx7wZj5sOtDE6CO7IS6ahlPb0nzXHWZJBUuToK6NWqrYf93MGT26V71uJvMWHZHJkzr6yD1HRh8idkcuqnYiTBqHmx8waTOtWXvchOIg/va3oak200g3/GeVGZsS1iCyX6x1Jvv81PMRHmfEc5tlxCtkKBujQPfmwCYeOnp+3pFm/H11Hds24ACTInc8sNm6KUlF/3ObBz9zVOtn+PoAdPDHm7j0Euj6LEQk2SGYHI2Q3A/6B3bsXN5srCBYKk1cypggnrUKPDxc267hGiFBHVrZK42ueTx08+8f8JtpuZ2xirbzpfylqkrMmR2y4+HDoAp95ghmiM7Wz6mcZJ2uI1DL00l3WEmZvd+bhYdibOFNsmAsVjMArEYGXoRrkuCenu0NpOkA88/OzNk8MWmh5tsw4RpZTGkr4SxC9ru7Z33SwgIgTW/bfnxvZ9B3zGd20d05DXg3xvqT8okaWua5qof3WdSUGWSVLgwCertKdxrFve0tATf28cMoWR9dfrjeXvS3gNLXetDL40CQmHGr2H/WnP+po7nm8VCtma9NOcXCGNvNF/LeHrLgqNNaYWj+0+ngEpQFy7MqqCulJqtlEpXSmUppR5r4fGblFJpDf82KqXG2r+pTpLZkMo45NKWH28Mzin/bf9cWsP2JWYsu8/w9o+fdJf5+L/mt6cn6uD0fqMdHU9vasav4JI/mjaJs3l5nS7slZ9ihuEihjq7VUK0qt2grpTyBl4E5gAjgBuUUs2n/g8AM7XWY4A/Ai/bu6FOk7Ha7ATUPEulUegAU8N8+5IzA29L8rZD0V6YcIt1r+3jBxf/Hgr3mPH1RnuXQ8QQk17ZWT0jYNoDJniJloU2Cep9x5hPaEK4KGt+kycDWVrr/VrrGuBdYG7TA7TWG7XWpQ3f/gB4RhpF1VGTGZLYSi+90YTbzNZm+9a2fVzKW+ATACOvtb4NI+aa8e5vnjK1YipLIHuDfXrpwjqNuepH0mToRbg8a4J6DJDT5PvchvtacyewsqUHlFKLlFLblFLbioqKrG+ls+z7BrSl9SyVRkMvM9ks299o/ZiaKlO8a+TVZvGPtRoXJFUcMbnr6StMuqO1BbxE54UlmB2haqsk80W4PGuCekvFtVusD6uUugAT1B9t6XGt9cta6yStdVJkZKT1rXSWjFWm/kd7v8g+fjDuBpPVUlHY8jF7Pm0o3mXl0EtTcVNMj33Dc6buekicyTMXXaOxsBdIT124PGuCei7Qv8n3scBZSx2VUmOAV4G5WusS+zTPiSz1Jutk8CXg5d3+8RNuM1ktqe+0/HjKf08X7+qIi56A+hrI22aGXmQji67TmKveoxeEDXJuW4RohzVBfSuQqJRKUEr5AQuA5U0PUErFAR8Bt2itM+zfTCfI3WrqorSW9dJcRKIpxrX9rbM3uijZBwfXn1m8y1bhg2Dy3eZrGXrpWiFxpiRE9FiZUBYur93/oVrrOuB+YDWwF1imtd6tlLpXKXVvw2G/A8KBl5RSqUqpbQ5rcVdp3BBj0IXWP2fibWaBSvb6M+9vqXhXR1z4W7jhXeg/pXPnEbbx9jWLxcYucHZLhGiX0p3Zxb4TkpKS9LZtLhz7XzrX1Chf+Ln1z6mthqeHmt79da+Y+yz18I+RJhXupmWOaasQottQSiVrrVtdWCKfJVtSlgOFu9vfyLk53wBT0nbPpyYdEiDr67aLdwkhhB1JUG9Je6tI2zLxNlNLJa2hV56ypO3iXUIIYUcS1FuSscYUyooYYvtz+442Gyhsf9P64l1CCGEnEtSbq6mCA9+ZVaQdzVSZcKtZ2r/y16YWtwy9CCG6iAT15rK/h7oTMMTG8fSmRs8ze4Du+tD64l1CCGEHEtSby1htAvKA6e0f25oewTCqob6L9NKFEF1Iys011daGGLaa9pCpFTJ6nj1aJoQQVpGeelOFe0y1xc4MvTSKGAzzXjO9diGE6CIS1JvKaEhltDU/XQghXIQE9aYyVpuVn61tiCGEEC7O/YK61nBgnf3PW3XU7Pspi4SEEG7M/YL69rfgzStNXXF7yvq6YUOMDqwiFUIIF+F+QX3sDTD4Yvj8YVNjxV4yVpnl/P1kZxshhPtyv6Du4wfzl0DsJPjwrvb3BbVGfZ3ZECNxltTLFkK4NfeMYH6BcON7EJ4I794EucmdO9+eT+BEmX1SGYUQwoncM6gDBITCLR9Bzwh4+zooSrf9HPV18NWT8OGdphCXpDIKIdyc+wZ1gOC+cOsn4O0Hb10NZYesf+7xw/DWVbD+GVOA684vwa+no1oqhBBdwr2DOpjNnG/+CGoqYck1UFHU/nP2fwv/Pg/yU+Caf8NV/zQbXAghhJtz/6AO0HeU2SruWJ4ZijlxvOXjLPXw7V9Mrz4gDO5eK/tOCiE8imcEdYC4qTD/LSjYDe/eCLUnzny8ogj+ey18+2cY8xNYtBb6DHNOW4UQwkE8J6iDyV65ejFkr4cP7jAToQDZG2DxdDj0gxlquWaxjJ8LITyS55XeHXM9VJfCykfgswcgfDB880cITYCbPzRDNUII4aE8L6gDTFkE1UfNUAvAyGvhyufAv5dz2yWEEA7mmUEdYOaj4BcE/r3N7kMd3W9UCCHciOcGdaXg3Pud3QohhOhSVk2UKqVmK6XSlVJZSqnHWnh8mFJqk1LqpFLqV/ZvphBCCGu021NXSnkDLwKXALnAVqXUcq31niaHHQUeAK52RCOFEEJYx5qe+mQgS2u9X2tdA7wLzG16gNa6UGu9Fah1QBuFEEJYyZqgHgPkNPk+t+E+mymlFimltimlthUVWbGcXwghhE2sCeotpY3ojryY1vplrXWS1jopMjKyI6cQQgjRBmuCei7Qv8n3sUC+Y5ojhBCiM6wJ6luBRKVUglLKD1gALHdss4QQQnREu9kvWus6pdT9wGrAG3hNa71bKXVvw+OLlVJ9gW1AL8CilHoIGKG1bqVcohBCCEdQWndoeLzzL6xUEXCwg0+PAIrt2BxX4GnX5GnXA553TZ52PeB519TS9QzQWrc6Kem0oN4ZSqltWuskZ7fDnjztmjztesDzrsnTrgc875o6cj2eVXpXCCG6OQnqQgjhQdw1qL/s7AY4gKddk6ddD3jeNXna9YDnXZPN1+OWY+pCCCFa5q49dSGEEC2QoC6EEB7E7YJ6e7Xd3ZFSKlsptVMplaqU2ubs9thKKfWaUqpQKbWryX1hSqkvlVKZDbehzmyjrVq5pt8rpfIa3qdUpdRlzmyjLZRS/ZVSa5VSe5VSu5VSDzbc75bvUxvX487vkb9SaotSakfDNT3ZcL9N75Fbjak31HbPoEltd+CGZrXd3Y5SKhtI0lq75aIJpdQMoAJ4S2s9quG+vwFHtdZ/afjjG6q1ftSZ7bRFK9f0e6BCa/20M9vWEUqpaCBaa71dKRUMJGP2P1iIG75PbVzPfNz3PVJAT611hVLKF1gPPAhciw3vkbv11Nut7S66ntZ6HWajlKbmAm82fP0mbraBSivX5La01oe11tsbvi4H9mJKaLvl+9TG9bgtbVQ0fOvb8E9j43vkbkHdbrXdXYwG1iilkpVSi5zdGDuJ0lofBvMLCPRxcnvs5X6lVFrD8IxbDFU0p5SKB8YDm/GA96nZ9YAbv0dKKW+lVCpQCHyptbb5PXK3oG632u4uZprWegIwB/hZw0d/4Xr+BQwCxgGHgf9zams6QCkVBHwIPOQJBfdauB63fo+01vVa63GYEueTlVKjbD2HuwV1j6ztrrXOb7gtBD7GDDO5u4KGcc/G8c9CJ7en07TWBQ2/dBbgFdzsfWoYp/0QeFtr/VHD3W77PrV0Pe7+HjXSWpcB3wKzsfE9creg7nG13ZVSPRsmelBK9QRmAbvafpZbWA7c1vD1bcCnTmyLXTT+YjW4Bjd6nxom4f4D7NVaP9PkIbd8n1q7Hjd/jyKVUiENXwcAFwM/YuN75FbZLwANKUrPcrq2+1PObVHnKKUGYnrnYOrbv+Nu16SUWgqcjykTWgA8AXwCLAPigEPA9Vprt5l4bOWazsd8rNdANnBP41inq1NKTQe+B3YCloa7/wczDu1271Mb13MD7vsejcFMhHpjOtzLtNZ/UEqFY8N75HZBXQghROvcbfhFCCFEGySoCyGEB5GgLoQQHkSCuhBCeBAJ6kII4UEkqAshhAeRoC6EEB7k/wNdKe//LpFqnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 11s - loss: 1.6920 - accuracy: 0.4802\n",
      "test loss 1.9713692945480348\n",
      "test accuracy 0.4802\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = densenet_121.evaluate(x_test,y_test,verbose=2)\n",
    "print('test loss',loss)\n",
    "print('test accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train densenet_169\n",
    "densenet_169.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = densenet_169.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test your models. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement your code here.\n",
    "#test densenet_121 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test densenet_169 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Load the pre-trained models from Keras and evaluate them. (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 38, 38, 3)    0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 16, 16, 64)   9408        zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 16, 16, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 18, 18, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 8, 8, 64)     0           zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 8, 64)     256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 8, 8, 64)     0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 128)    8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 8, 128)    0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 8, 8, 96)     0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 8, 8, 96)     384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 8, 8, 96)     0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 128)    12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 8, 128)    0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 8, 8, 128)    0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 8, 8, 128)    0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 128)    16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 8, 128)    0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 8, 8, 160)    0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 8, 8, 160)    640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 8, 8, 160)    0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 8, 8, 128)    20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 8, 8, 128)    0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 8, 8, 192)    0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 8, 8, 192)    768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 8, 8, 192)    0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 8, 8, 128)    24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 8, 8, 128)    0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 8, 8, 224)    0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 8, 8, 224)    896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 8, 8, 224)    0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 8, 8, 128)    28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 8, 8, 128)    0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 8, 8, 256)    0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 8, 8, 256)    1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 8, 8, 256)    0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 8, 8, 128)    32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 4, 4, 128)    0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 128)    512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 4, 4, 128)    0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 4, 4, 160)    0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 4, 4, 160)    640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 4, 4, 160)    0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 4, 4, 192)    0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 4, 4, 192)    768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 4, 4, 192)    0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 4, 4, 224)    0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 4, 4, 224)    896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 4, 4, 224)    0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 4, 4, 256)    0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 4, 4, 256)    1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 4, 4, 256)    0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 4, 4, 128)    0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 4, 4, 288)    0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 4, 4, 288)    1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 4, 4, 288)    0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 4, 4, 128)    36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 4, 4, 128)    0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 4, 4, 320)    0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 4, 4, 320)    1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 4, 4, 320)    0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 4, 4, 128)    40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 4, 4, 128)    0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 4, 4, 352)    0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 4, 4, 352)    1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 4, 4, 352)    0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 4, 4, 128)    45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 4, 4, 128)    0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 4, 4, 384)    0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 4, 4, 384)    1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 4, 4, 384)    0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 4, 4, 128)    49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 4, 4, 128)    0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 4, 4, 416)    0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 4, 4, 416)    1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 4, 4, 416)    0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 4, 4, 128)    53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 4, 4, 448)    0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 4, 4, 448)    1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 4, 4, 448)    0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 4, 4, 128)    57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 4, 4, 480)    0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 4, 4, 480)    1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 4, 4, 480)    0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 4, 4, 128)    61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 4, 4, 512)    0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 4, 4, 512)    2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 4, 4, 512)    0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 4, 4, 256)    131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 2, 2, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 2, 2, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 2, 2, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 2, 2, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 2, 2, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 2, 2, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 2, 2, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 2, 2, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 2, 2, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 2, 2, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 2, 2, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 2, 2, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 2, 2, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 2, 2, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 2, 2, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 2, 2, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 2, 2, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 2, 2, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 2, 2, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 2, 2, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 2, 2, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 2, 2, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 2, 2, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 2, 2, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 2, 2, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 2, 2, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 2, 2, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 2, 2, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 2, 2, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 2, 2, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 2, 2, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 2, 2, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 2, 2, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 2, 2, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 2, 2, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 2, 2, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 2, 2, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 2, 2, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 2, 2, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 2, 2, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 2, 2, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 2, 2, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 2, 2, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 2, 2, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 2, 2, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 2, 2, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 2, 2, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 2, 2, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 2, 2, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 2, 2, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 2, 2, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 2, 2, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 2, 2, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 2, 2, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 2, 2, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 2, 2, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 2, 2, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 2, 2, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 2, 2, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 2, 2, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 2, 2, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 2, 2, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 2, 2, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 2, 2, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 2, 2, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 2, 2, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 2, 2, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 2, 2, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 2, 2, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 2, 2, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 2, 2, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 2, 2, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 2, 2, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 2, 2, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 2, 2, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 2, 2, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 2, 2, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 2, 2, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 2, 2, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 2, 2, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 2, 2, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 2, 2, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 2, 2, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 2, 2, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 2, 2, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 2, 2, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 2, 2, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 2, 2, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 2, 2, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 2, 2, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 2, 2, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 2, 2, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 2, 2, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 2, 2, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 2, 2, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 2, 2, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 1, 1, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 1, 1, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 1, 1, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 1, 1, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 1, 1, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 1, 1, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 1, 1, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 1, 1, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 1, 1, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 1, 1, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 1, 1, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 1, 1, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 1, 1, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 1, 1, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 1, 1, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 1, 1, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 1, 1, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 1, 1, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 1, 1, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 1, 1, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 1, 1, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 1, 1, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 1, 1, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 1, 1, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 1, 1, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 1, 1, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 1, 1, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 1, 1, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 1, 1, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 1, 1, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 1, 1, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 1, 1, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 1, 1, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 1, 1, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 1, 1, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 1, 1, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 1, 1, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 1, 1, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 1, 1, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 1, 1, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 1, 1, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 1, 1, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 1, 1, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 1, 1, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 1, 1, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 1, 1, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 1, 1, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 1, 1, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 1, 1, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 1, 1, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 1, 1, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 1, 1, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 1, 1, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 1, 1, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 1, 1, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 1, 1, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 1, 1, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 1, 1, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 1, 1, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 1, 1, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 1, 1, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 1, 1, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 1, 1, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 1, 1, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 1, 1, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 1, 1, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 1, 1, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 1, 1, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 1, 1, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           10250       global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 7,047,754\n",
      "Trainable params: 6,964,106\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# dense121_model = DenseNet121(include_top=False,weights='imagenet',input_shape=(32,32,3))\n",
    "\n",
    "# dense121_model.summary()\n",
    "\n",
    "base_model = DenseNet121(include_top=False,weights='imagenet',input_shape=(32,32,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) \n",
    "predictions = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 114s 3ms/sample - loss: 0.9859 - accuracy: 0.6702 - val_loss: 62.3670 - val_accuracy: 0.4938\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.7174 - accuracy: 0.7586 - val_loss: 0.5558 - val_accuracy: 0.8066\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.6961 - accuracy: 0.7675 - val_loss: 2.3136 - val_accuracy: 0.4654\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.6127 - accuracy: 0.7940 - val_loss: 1.0076 - val_accuracy: 0.6984\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.5473 - accuracy: 0.8175 - val_loss: 2.4486 - val_accuracy: 0.7570\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 95s 2ms/sample - loss: 0.6189 - accuracy: 0.7964 - val_loss: 0.7305 - val_accuracy: 0.7442\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.4416 - accuracy: 0.8489 - val_loss: 1.0407 - val_accuracy: 0.6622\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.3787 - accuracy: 0.8698 - val_loss: 0.6268 - val_accuracy: 0.7914\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 94s 2ms/sample - loss: 0.2618 - accuracy: 0.9098 - val_loss: 0.6469 - val_accuracy: 0.7976\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 93s 2ms/sample - loss: 0.3788 - accuracy: 0.8778 - val_loss: 1.2470 - val_accuracy: 0.6436\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.reshape((50000, 32, 32, 3)).astype('float32') / 255\n",
    "x_test = x_test.reshape((10000, 32, 32, 3)).astype('float32') / 255\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"  #选择哪一块gpu\n",
    "config = ConfigProto()\n",
    "config.allow_soft_placement=True #如果你指定的设备不存在，允许TF自动分配设备\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.8  #分配百分之七十的显存给程序使用，避免内存溢出，可以自己调整\n",
    "config.gpu_options.allow_growth = True   #按需分配显存，这个比较重要\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "# dense121_model = DenseNet121(blocks=[6, 12, 24, 16],include_top=False,weights='imagenet',input_shape=(32,32,3))\n",
    "\n",
    "\n",
    "# y_train = to_categorical(y_train, 10)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "session.close()\n",
    "# implement your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 9s - loss: 2.3811 - accuracy: 0.1001\n",
      "test loss 2.4549483810424806\n",
      "test accuracy 0.100089446\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = dense121_model.evaluate(x_test,y_test,verbose=2)\n",
    "print('test loss',loss)\n",
    "print('test accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense169_model = DenseNet121(include_top=False,weights=None,input_shape=(32,32,3))\n",
    "\n",
    "dense169_model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "dense169_model.fit(x_train, y_train)\n",
    "history = dense169_model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Analysis your results. (20 marks)\n",
    "Compare the performance of your models with the following analysis. Both English and Chinese answers are acceptable.\n",
    "1. Is your implementation of DenseNet-169 better than DenseNet-121? If yes, how is the improvement? If no, try to figure the reason out based on your experiments. (10 marks)\n",
    "\n",
    "Answer:\n",
    "\n",
    "2. Compare the results of your implementation with the pre-trained models from Keras. (10 marks)\n",
    "\n",
    "Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
