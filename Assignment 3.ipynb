{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Character-Level Recurrent Neural Network by PyTorch\n",
    "\n",
    "In this assignment, you are required to implement Character-Level RNN just as we have learned in the class. However, the difference is we use another dataset in this assignment.\n",
    "\n",
    "Read through the tutorial [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) that builds a char-rnn that is used to classify names by their country of origin, which is introduced in the class. It is recommended that you can reproduce the tutorial’s results on the provided name dataset before moving on (notebook for Lecture 7), since the neural network architectures remain largely the same. Make sure you try your best to understand the dimensions of each layer (e.g. which ones can stay the same, and which are hyperparameters for us to tweak).\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Code implementation. (20 marks)\n",
    "2. Experimentation and analysis (80 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNS4OZXxMZ-A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Download and unzip files\n",
    "# !pip3 install scikit-learn\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_test.txt\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_val.zip\n",
    "# wget http://computational-linguistics-class.org/homework/nn-lms/cities_train.zip\n",
    "# !sudo apt-get install unzip\n",
    "# !unzip cities_val.zip \n",
    "# !unzip cities_train.zip \n",
    "# from os.path import exists\n",
    "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "#!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "# !pip3 install torch torchvision\n",
    "  \n",
    "import torch\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIJxbqMDNTTl"
   },
   "outputs": [],
   "source": [
    "#Verfiy file download\n",
    "# !head train/af.txt\n",
    "# !printf \"\\n\"\n",
    "# !head val/af.txt\n",
    "# !printf \"\\n\"\n",
    "# !head cities_test.txt\n",
    "# !printf \"\\n\"\n",
    "#Verify CUDA acceleration should print cuda:0\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation (20 marks)\n",
    "\n",
    "**You should implement all the following functions and you are not allowed to delete any of them. Of course you can add more functions based on this skeleton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwB5RzvfOGr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: train/af.txt\n",
      "reading file: train/cn.txt\n",
      "reading file: train/de.txt\n",
      "reading file: train/fi.txt\n",
      "reading file: train/fr.txt\n",
      "reading file: train/in.txt\n",
      "reading file: train/ir.txt\n",
      "reading file: train/pk.txt\n",
      "reading file: train/za.txt\n",
      "reading file: val/af.txt\n",
      "reading file: val/cn.txt\n",
      "reading file: val/de.txt\n",
      "reading file: val/fi.txt\n",
      "reading file: val/fr.txt\n",
      "reading file: val/in.txt\n",
      "reading file: val/ir.txt\n",
      "reading file: val/pk.txt\n",
      "reading file: val/za.txt\n"
     ]
    }
   ],
   "source": [
    "#main_classify.py\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import unicodedata\n",
    "from io import open\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "Don't change these constants for the classification task.\n",
    "You may use different copies for the sentence generation model.\n",
    "'''\n",
    "languages = [\"af\", \"cn\", \"de\", \"fi\", \"fr\", \"in\", \"ir\", \"pk\", \"za\"]\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "n_languages = len(languages)\n",
    "\n",
    "'''\n",
    "Returns the words of the language specified by reading it from the data folder\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "Return: A nx1 array containing the words of the specified language\n",
    "'''\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def getWords(baseDir, lang, train = True):\n",
    "    if train:\n",
    "        baseDir = baseDir + 'train'\n",
    "    else:\n",
    "        baseDir = baseDir + 'val'\n",
    "    filename = baseDir +'/' + lang + '.txt'\n",
    "    print(\"reading file:\",filename)\n",
    "    #Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）\n",
    "    words = open(filename,encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(word) for word in words]\n",
    "\n",
    "#test getWords\n",
    "# words = getWords('',languages[0])\n",
    "# print(words)\n",
    "\n",
    "'''\n",
    "Returns a label corresponding to the language\n",
    "For example it returns an array of 0s for af\n",
    "Return: A nx1 array as integers containing index of the specified language in the \"languages\" array\n",
    "'''\n",
    "def getLabels(lang, length):\n",
    "    index = languages.index(lang)\n",
    "    labels = np.zeros(length)\n",
    "    labels[index] = 1\n",
    "    \n",
    "#     labels = [index]\n",
    "    return labels\n",
    "\n",
    "#test getLabels\n",
    "# labels = getLabels(languages[0], len(languages))\n",
    "# print(labels)#[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "\n",
    "'''\n",
    "Returns all the laguages and labels after reading it from the file\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "You may assume that the files exist in baseDir and have the same names.\n",
    "Return: X, y where X is nx1 and y is nx1\n",
    "'''\n",
    "def readData(baseDir, train=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0,len(languages)):\n",
    "        X.append(getWords(baseDir,languages[i],train))\n",
    "        y.append(languages[i])\n",
    "    return X,y\n",
    "#test  readData\n",
    "\n",
    "train_X,train_y = readData('')\n",
    "val_X,val_y = readData('',False)\n",
    "\n",
    "# print(len(X))\n",
    "# print(len(y))\n",
    "# print(X[0])\n",
    "# print(y[0])\n",
    "\n",
    "'''\n",
    "Convert a line/word to a pytorch tensor of numbers\n",
    "Refer the tutorial in the spec\n",
    "Return: A tensor corresponding to the given line\n",
    "'''\n",
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line),1,n_letters)\n",
    "    for li,letter in enumerate(line):\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "#test line_to_tensor\n",
    "# tensor = line_to_tensor(\"Yang\")\n",
    "# print(tensor)\n",
    "# print(tensor.shape) #[4, 1, 57]\n",
    "\n",
    "'''\n",
    "Returns the category/class of the output from the neural network\n",
    "Input: Output of the neural networks (class probabilities)\n",
    "Return: A tuple with (language, language_index)\n",
    "        language: \"af\", \"cn\", etc.\n",
    "        language_index: 0, 1, etc.\n",
    "'''\n",
    "def category_from_output(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "#     print(\"top_n\",top_n)\n",
    "#     print(\"top_i\",top_i)\n",
    "    language_i = top_i[0].item()\n",
    "    return languages[language_i], language_i\n",
    "\n",
    "'''\n",
    "Get a random input output pair to be used for training \n",
    "Refer the tutorial in the spec\n",
    "'''\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def random_training_pair(X, y):\n",
    "    language = randomChoice(y)\n",
    "    language_index = y.index(language)\n",
    "    line = randomChoice(X[language_index])\n",
    "    language_tensor = torch.tensor([language_index],dtype=torch.long)\n",
    "    line_tensor = line_to_tensor(line)\n",
    "    return language,line ,language_tensor,line_tensor\n",
    "    \n",
    "#test random_training_pair\n",
    "# language,line ,language_tensor,line_tensor = random_training_pair(train_X,train_y)\n",
    "# print(language)\n",
    "# print(line)\n",
    "# print(language_tensor)\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: a list of class labels as integers\n",
    "'''\n",
    "#输入：X是要预测的字符串，y是对应的标签\n",
    "#输出：预测得到的前三个最高的类别\n",
    "def predict(model, X, y):\n",
    "    \n",
    "    line_tensor = line_to_tensor(X)\n",
    "    language_tensor = torch.tensor([languages.index(y)],dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden()\n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = model(line_tensor[i], hidden)\n",
    "\n",
    "        language, language_index = category_from_output(output)\n",
    "    \n",
    "    return language\n",
    "\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: The accuracy of the given model on the given input X and target y\n",
    "'''\n",
    "def calculateAccuracy(model, X, y):\n",
    "    count = 0\n",
    "    num = 0\n",
    "    for i in range(0,len(y)):\n",
    "        num += len(X[i])\n",
    "        for j in range(0,len(X[i])):\n",
    "            language = predict(model,X[i][j],y[i])\n",
    "            if (language == y[i]):\n",
    "                count+=1\n",
    "    acc = count/num\n",
    "    print('There is %s samples,Accuracy=%s'%(num,acc))\n",
    "    return acc\n",
    "\n",
    "'''\n",
    "Train the model for one epoch/one training word.\n",
    "Ensure that it runs within 3 seconds.\n",
    "Input: X and y are lists of words as strings and classes as integers respectively\n",
    "Returns: You may return anything\n",
    "'''\n",
    "def trainOneEpoch(model, criterion, optimizer, X, y):\n",
    "    \n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(X.size()[0]):\n",
    "        output, hidden = model(X[i], hidden)\n",
    "        \n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "'''\n",
    "Use this to train and save your classification model. \n",
    "Save your model with the filename \"model_classify\"\n",
    "'''\n",
    "def run(model,criterion):\n",
    "    n_iters = 100000\n",
    "    print_every = 5000\n",
    "    plot_every = 1000\n",
    "    \n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    learning_rate = 0.005 \n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        language,line,language_tensor,line_tensor = random_training_pair(train_X,train_y)\n",
    "        #trainOneEpoch(model, criterion, optimizer, X, y)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "        output, loss = trainOneEpoch(model,criterion,optimizer,line_tensor,language_tensor)\n",
    "        current_loss += loss\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = category_from_output(output)\n",
    "            correct = '✓' if guess == language else '✗ (%s)' % language\n",
    "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, \\\n",
    "                                    timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            with torch.no_grad():\n",
    "                hidden = model.init_hidden()\n",
    "                language,line,language_tensor,line_tensor = random_training_pair(val_X,val_y)\n",
    "                for i in range(line_tensor.size()[0]):\n",
    "                    output_val, hidden = model(line_tensor[i], hidden)\n",
    "                loss_val = criterion(output_val,language_tensor)\n",
    "            val_losses.append(loss_val)\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "    torch.save(model,'model_classify.pkl')\n",
    "    return val_losses,all_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbOusBLKPsrx"
   },
   "outputs": [],
   "source": [
    "#models.py\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "Please add default values for all the parameters of __init__.\n",
    "'''\n",
    "class CharRNNClassify(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNNClassify, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)  \n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)  \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        combined = torch.cat((input,hidden),1)\n",
    "        hidden = self.i2h(combined)\n",
    "        hidden = self.tanh(hidden)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "criterion = nn.NLLLoss()\n",
    "CharRnn = CharRNNClassify(n_letters, n_hidden, n_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 14s) 1.8689 kisande / in ✗ (de)\n",
      "10000 10% (0m 29s) 0.0817 hanock beza / za ✓\n",
      "15000 15% (0m 45s) 0.2976 calves / fr ✓\n",
      "20000 20% (1m 2s) 0.5197 sekamkhaza / za ✓\n",
      "25000 25% (1m 19s) 0.1949 nzai / za ✓\n",
      "30000 30% (1m 34s) 1.6833 taraf jundik / fi ✗ (af)\n",
      "35000 35% (1m 50s) 3.0556 puebla de montalban / ir ✗ (de)\n",
      "40000 40% (2m 6s) 0.7388 chirkingile / in ✓\n",
      "45000 45% (2m 21s) 0.9957 shahrake mahdavi / ir ✓\n",
      "50000 50% (2m 36s) 1.7547 huttenheim / de ✗ (fr)\n",
      "55000 55% (2m 52s) 2.8963 chak eightyfour / fr ✗ (pk)\n",
      "60000 60% (3m 7s) 0.1806 sal'miniulia / in ✓\n",
      "65000 65% (3m 22s) 1.8561 la borie de bagas / de ✗ (fr)\n",
      "70000 70% (3m 37s) 0.8360 nang inh / in ✓\n",
      "75000 75% (3m 52s) 0.3329 spanzati / za ✓\n",
      "80000 80% (4m 8s) 0.7742 tirma tid / ir ✓\n",
      "85000 85% (4m 23s) 0.1394 lalizolle / fr ✓\n"
     ]
    }
   ],
   "source": [
    "val_losses,all_losses = run(CharRnn,criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation and Analysis (80 marks)\n",
    "\n",
    "Complete the following analysis on the city names dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code to output accuracy on the validation set (10 marks).  Use a confusion matrix plot to support your answer (10 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is %s samples,Accuracy=%s 27000 0.5212962962962963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5212962962962963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateAccuracy(CharRnn, train_X, train_y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 900 samples,Accuracy=0.48777777777777775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48777777777777775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateAccuracy(CharRnn, val_X, val_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "confusion = torch.zeros(n_languages, n_languages)\n",
    "\n",
    "for i in range(0,len(val_y)):\n",
    "    for j in range(0,len(val_X[i])):\n",
    "        guess = predict(CharRnn,val_X[i][j],val_y[i])\n",
    "        language_i = languages.index(val_y[i])\n",
    "        guess_i = languages.index(guess)\n",
    "        confusion[language_i][guess_i] += 1\n",
    "                \n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + languages, rotation=90)\n",
    "ax.set_yticklabels([''] + languages)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Periodically compute the loss on the validation set, and create a plot with the training and validation loss as training progresses (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no property 'colors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8368842dfb99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mColors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mColors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2824\u001b[0m     return gca().plot(\n\u001b[0;32m   2825\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2826\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 419\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 419\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[1;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m    994\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"set_{k}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0m\u001b[0;32m    997\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m    998\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Line2D' object has no property 'colors'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses,color='b')\n",
    "plt.plot(val_losses,color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Experiment with the learning rate. You can try a few different learning rates and observe how this affects the loss. Another common practice is to drop the learning rate when the loss has plateaued. Use plots to explain your experiments and their effects on the loss (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Experiment with the size of the hidden layer or the model architecture How does this affect validation accuracy (20 marks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw6_skeleton.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
